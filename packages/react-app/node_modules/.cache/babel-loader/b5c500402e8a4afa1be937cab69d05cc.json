{"ast":null,"code":"'use strict';\n\nvar _objectSpread = require(\"/Users/yenerkaraca/Documents/GitHub/eth-app/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/objectSpread2\");\n\nvar _asyncToGenerator = require(\"/Users/yenerkaraca/Documents/GitHub/eth-app/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/asyncToGenerator\");\n\nvar _regeneratorRuntime = require(\"/Users/yenerkaraca/Documents/GitHub/eth-app/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\");\n\nvar _awaitAsyncGenerator = require(\"/Users/yenerkaraca/Documents/GitHub/eth-app/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/awaitAsyncGenerator\");\n\nvar _wrapAsyncGenerator = require(\"/Users/yenerkaraca/Documents/GitHub/eth-app/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/wrapAsyncGenerator\");\n\nvar _asyncIterator = require(\"/Users/yenerkaraca/Documents/GitHub/eth-app/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/asyncIterator\");\n\nvar errCode = require('err-code');\n\nvar UnixFS = require('ipfs-unixfs');\n\nvar persist = require('../../utils/persist');\n\nvar _require = require('ipld-dag-pb'),\n    DAGNode = _require.DAGNode,\n    DAGLink = _require.DAGLink;\n\nvar all = require('it-all');\n\nvar parallelBatch = require('it-parallel-batch');\n\nvar mh = require('multihashing-async').multihash;\n\nvar dagBuilders = {\n  flat: require('./flat'),\n  balanced: require('./balanced'),\n  trickle: require('./trickle')\n};\n\nfunction buildFileBatch(_x, _x2, _x3, _x4) {\n  return _buildFileBatch.apply(this, arguments);\n}\n\nfunction _buildFileBatch() {\n  _buildFileBatch = _wrapAsyncGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee(file, source, block, options) {\n    var count, previous, bufferImporter, _iteratorNormalCompletion, _didIteratorError, _iteratorError, _iterator, _step, _value, entry;\n\n    return _regeneratorRuntime.wrap(function _callee$(_context) {\n      while (1) {\n        switch (_context.prev = _context.next) {\n          case 0:\n            count = -1;\n\n            if (typeof options.bufferImporter === 'function') {\n              bufferImporter = options.bufferImporter;\n            } else {\n              bufferImporter = require('./buffer-importer');\n            }\n\n            _iteratorNormalCompletion = true;\n            _didIteratorError = false;\n            _context.prev = 4;\n            _iterator = _asyncIterator(parallelBatch(bufferImporter(file, source, block, options), options.blockWriteConcurrency));\n\n          case 6:\n            _context.next = 8;\n            return _awaitAsyncGenerator(_iterator.next());\n\n          case 8:\n            _step = _context.sent;\n            _iteratorNormalCompletion = _step.done;\n            _context.next = 12;\n            return _awaitAsyncGenerator(_step.value);\n\n          case 12:\n            _value = _context.sent;\n\n            if (_iteratorNormalCompletion) {\n              _context.next = 30;\n              break;\n            }\n\n            entry = _value;\n            count++;\n\n            if (!(count === 0)) {\n              _context.next = 21;\n              break;\n            }\n\n            previous = entry;\n            return _context.abrupt(\"continue\", 27);\n\n          case 21:\n            if (!(count === 1)) {\n              _context.next = 25;\n              break;\n            }\n\n            _context.next = 24;\n            return previous;\n\n          case 24:\n            previous = null;\n\n          case 25:\n            _context.next = 27;\n            return entry;\n\n          case 27:\n            _iteratorNormalCompletion = true;\n            _context.next = 6;\n            break;\n\n          case 30:\n            _context.next = 36;\n            break;\n\n          case 32:\n            _context.prev = 32;\n            _context.t0 = _context[\"catch\"](4);\n            _didIteratorError = true;\n            _iteratorError = _context.t0;\n\n          case 36:\n            _context.prev = 36;\n            _context.prev = 37;\n\n            if (!(!_iteratorNormalCompletion && _iterator.return != null)) {\n              _context.next = 41;\n              break;\n            }\n\n            _context.next = 41;\n            return _awaitAsyncGenerator(_iterator.return());\n\n          case 41:\n            _context.prev = 41;\n\n            if (!_didIteratorError) {\n              _context.next = 44;\n              break;\n            }\n\n            throw _iteratorError;\n\n          case 44:\n            return _context.finish(41);\n\n          case 45:\n            return _context.finish(36);\n\n          case 46:\n            if (!previous) {\n              _context.next = 50;\n              break;\n            }\n\n            previous.single = true;\n            _context.next = 50;\n            return previous;\n\n          case 50:\n          case \"end\":\n            return _context.stop();\n        }\n      }\n    }, _callee, null, [[4, 32, 36, 46], [37,, 41, 45]]);\n  }));\n  return _buildFileBatch.apply(this, arguments);\n}\n\nvar reduce = function reduce(file, block, options) {\n  return /*#__PURE__*/function () {\n    var _ref = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2(leaves) {\n      var leaf, _yield$block$get, _buffer, multihash, f, links, node, buffer, cid;\n\n      return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n        while (1) {\n          switch (_context2.prev = _context2.next) {\n            case 0:\n              if (!(leaves.length === 1 && leaves[0].single && options.reduceSingleLeafToSelf)) {\n                _context2.next = 15;\n                break;\n              }\n\n              leaf = leaves[0];\n\n              if (!(leaf.cid.codec === 'raw' && (file.mtime !== undefined || file.mode !== undefined))) {\n                _context2.next = 14;\n                break;\n              }\n\n              _context2.next = 5;\n              return block.get(leaf.cid, options);\n\n            case 5:\n              _yield$block$get = _context2.sent;\n              _buffer = _yield$block$get.data;\n              leaf.unixfs = new UnixFS({\n                type: 'file',\n                mtime: file.mtime,\n                mode: file.mode,\n                data: _buffer\n              });\n              multihash = mh.decode(leaf.cid.multihash);\n              _buffer = new DAGNode(leaf.unixfs.marshal()).serialize();\n              _context2.next = 12;\n              return persist(_buffer, block, _objectSpread(_objectSpread({}, options), {}, {\n                codec: 'dag-pb',\n                hashAlg: multihash.name,\n                cidVersion: options.cidVersion\n              }));\n\n            case 12:\n              leaf.cid = _context2.sent;\n              leaf.size = _buffer.length;\n\n            case 14:\n              return _context2.abrupt(\"return\", {\n                cid: leaf.cid,\n                path: file.path,\n                unixfs: leaf.unixfs,\n                size: leaf.size\n              });\n\n            case 15:\n              // create a parent node and add all the leaves\n              f = new UnixFS({\n                type: 'file',\n                mtime: file.mtime,\n                mode: file.mode\n              });\n              links = leaves.filter(function (leaf) {\n                if (leaf.cid.codec === 'raw' && leaf.size) {\n                  return true;\n                }\n\n                if (!leaf.unixfs.data && leaf.unixfs.fileSize()) {\n                  return true;\n                }\n\n                return Boolean(leaf.unixfs.data.length);\n              }).map(function (leaf) {\n                if (leaf.cid.codec === 'raw') {\n                  // node is a leaf buffer\n                  f.addBlockSize(leaf.size);\n                  return new DAGLink(leaf.name, leaf.size, leaf.cid);\n                }\n\n                if (!leaf.unixfs.data) {\n                  // node is an intermediate node\n                  f.addBlockSize(leaf.unixfs.fileSize());\n                } else {\n                  // node is a unixfs 'file' leaf node\n                  f.addBlockSize(leaf.unixfs.data.length);\n                }\n\n                return new DAGLink(leaf.name, leaf.size, leaf.cid);\n              });\n              node = new DAGNode(f.marshal(), links);\n              buffer = node.serialize();\n              _context2.next = 21;\n              return persist(buffer, block, options);\n\n            case 21:\n              cid = _context2.sent;\n              return _context2.abrupt(\"return\", {\n                cid: cid,\n                path: file.path,\n                unixfs: f,\n                size: buffer.length + node.Links.reduce(function (acc, curr) {\n                  return acc + curr.Tsize;\n                }, 0)\n              });\n\n            case 23:\n            case \"end\":\n              return _context2.stop();\n          }\n        }\n      }, _callee2);\n    }));\n\n    return function (_x5) {\n      return _ref.apply(this, arguments);\n    };\n  }();\n};\n\nvar fileBuilder = /*#__PURE__*/function () {\n  var _ref2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3(file, source, block, options) {\n    var dagBuilder, roots;\n    return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n      while (1) {\n        switch (_context3.prev = _context3.next) {\n          case 0:\n            dagBuilder = dagBuilders[options.strategy];\n\n            if (dagBuilder) {\n              _context3.next = 3;\n              break;\n            }\n\n            throw errCode(new Error(\"Unknown importer build strategy name: \".concat(options.strategy)), 'ERR_BAD_STRATEGY');\n\n          case 3:\n            _context3.next = 5;\n            return all(dagBuilder(buildFileBatch(file, source, block, options), reduce(file, block, options), options));\n\n          case 5:\n            roots = _context3.sent;\n\n            if (!(roots.length > 1)) {\n              _context3.next = 8;\n              break;\n            }\n\n            throw errCode(new Error('expected a maximum of 1 roots and got ' + roots.length), 'ETOOMANYROOTS');\n\n          case 8:\n            return _context3.abrupt(\"return\", roots[0]);\n\n          case 9:\n          case \"end\":\n            return _context3.stop();\n        }\n      }\n    }, _callee3);\n  }));\n\n  return function fileBuilder(_x6, _x7, _x8, _x9) {\n    return _ref2.apply(this, arguments);\n  };\n}();\n\nmodule.exports = fileBuilder;","map":{"version":3,"sources":["/Users/yenerkaraca/Documents/GitHub/eth-app/node_modules/ipfs-unixfs-importer/src/dag-builder/file/index.js"],"names":["errCode","require","UnixFS","persist","DAGNode","DAGLink","all","parallelBatch","mh","multihash","dagBuilders","flat","balanced","trickle","buildFileBatch","file","source","block","options","count","bufferImporter","blockWriteConcurrency","entry","previous","single","reduce","leaves","length","reduceSingleLeafToSelf","leaf","cid","codec","mtime","undefined","mode","get","buffer","data","unixfs","type","decode","marshal","serialize","hashAlg","name","cidVersion","size","path","f","links","filter","fileSize","Boolean","map","addBlockSize","node","Links","acc","curr","Tsize","fileBuilder","dagBuilder","strategy","Error","roots","module","exports"],"mappings":"AAAA;;;;;;;;;;;;;;AAEA,IAAMA,OAAO,GAAGC,OAAO,CAAC,UAAD,CAAvB;;AACA,IAAMC,MAAM,GAAGD,OAAO,CAAC,aAAD,CAAtB;;AACA,IAAME,OAAO,GAAGF,OAAO,CAAC,qBAAD,CAAvB;;eAIIA,OAAO,CAAC,aAAD,C;IAFTG,O,YAAAA,O;IACAC,O,YAAAA,O;;AAEF,IAAMC,GAAG,GAAGL,OAAO,CAAC,QAAD,CAAnB;;AACA,IAAMM,aAAa,GAAGN,OAAO,CAAC,mBAAD,CAA7B;;AACA,IAAMO,EAAE,GAAGP,OAAO,CAAC,oBAAD,CAAP,CAA8BQ,SAAzC;;AAEA,IAAMC,WAAW,GAAG;AAClBC,EAAAA,IAAI,EAAEV,OAAO,CAAC,QAAD,CADK;AAElBW,EAAAA,QAAQ,EAAEX,OAAO,CAAC,YAAD,CAFC;AAGlBY,EAAAA,OAAO,EAAEZ,OAAO,CAAC,WAAD;AAHE,CAApB;;SAMiBa,c;;;;;+EAAjB,iBAAiCC,IAAjC,EAAuCC,MAAvC,EAA+CC,KAA/C,EAAsDC,OAAtD;AAAA;;AAAA;AAAA;AAAA;AAAA;AACMC,YAAAA,KADN,GACc,CAAC,CADf;;AAKE,gBAAI,OAAOD,OAAO,CAACE,cAAf,KAAkC,UAAtC,EAAkD;AAChDA,cAAAA,cAAc,GAAGF,OAAO,CAACE,cAAzB;AACD,aAFD,MAEO;AACLA,cAAAA,cAAc,GAAGnB,OAAO,CAAC,mBAAD,CAAxB;AACD;;AATH;AAAA;AAAA;AAAA,uCAW4BM,aAAa,CAACa,cAAc,CAACL,IAAD,EAAOC,MAAP,EAAeC,KAAf,EAAsBC,OAAtB,CAAf,EAA+CA,OAAO,CAACG,qBAAvD,CAXzC;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAWmBC,YAAAA,KAXnB;AAYIH,YAAAA,KAAK;;AAZT,kBAcQA,KAAK,KAAK,CAdlB;AAAA;AAAA;AAAA;;AAeMI,YAAAA,QAAQ,GAAGD,KAAX;AAfN;;AAAA;AAAA,kBAiBeH,KAAK,KAAK,CAjBzB;AAAA;AAAA;AAAA;;AAAA;AAkBM,mBAAMI,QAAN;;AAlBN;AAmBMA,YAAAA,QAAQ,GAAG,IAAX;;AAnBN;AAAA;AAsBI,mBAAMD,KAAN;;AAtBJ;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA,iBAyBMC,QAzBN;AAAA;AAAA;AAAA;;AA0BIA,YAAAA,QAAQ,CAACC,MAAT,GAAkB,IAAlB;AA1BJ;AA2BI,mBAAMD,QAAN;;AA3BJ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,G;;;;AA+BA,IAAME,MAAM,GAAG,SAATA,MAAS,CAACV,IAAD,EAAOE,KAAP,EAAcC,OAAd,EAA0B;AACvC;AAAA,wEAAO,kBAAgBQ,MAAhB;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA,oBACDA,MAAM,CAACC,MAAP,KAAkB,CAAlB,IAAuBD,MAAM,CAAC,CAAD,CAAN,CAAUF,MAAjC,IAA2CN,OAAO,CAACU,sBADlD;AAAA;AAAA;AAAA;;AAEGC,cAAAA,IAFH,GAEUH,MAAM,CAAC,CAAD,CAFhB;;AAAA,oBAICG,IAAI,CAACC,GAAL,CAASC,KAAT,KAAmB,KAAnB,KAA6BhB,IAAI,CAACiB,KAAL,KAAeC,SAAf,IAA4BlB,IAAI,CAACmB,IAAL,KAAcD,SAAvE,CAJD;AAAA;AAAA;AAAA;;AAAA;AAAA,qBAO4BhB,KAAK,CAACkB,GAAN,CAAUN,IAAI,CAACC,GAAf,EAAoBZ,OAApB,CAP5B;;AAAA;AAAA;AAOWkB,cAAAA,OAPX,oBAOKC,IAPL;AASDR,cAAAA,IAAI,CAACS,MAAL,GAAc,IAAIpC,MAAJ,CAAW;AACvBqC,gBAAAA,IAAI,EAAE,MADiB;AAEvBP,gBAAAA,KAAK,EAAEjB,IAAI,CAACiB,KAFW;AAGvBE,gBAAAA,IAAI,EAAEnB,IAAI,CAACmB,IAHY;AAIvBG,gBAAAA,IAAI,EAAED;AAJiB,eAAX,CAAd;AAOM3B,cAAAA,SAhBL,GAgBiBD,EAAE,CAACgC,MAAH,CAAUX,IAAI,CAACC,GAAL,CAASrB,SAAnB,CAhBjB;AAiBD2B,cAAAA,OAAM,GAAG,IAAIhC,OAAJ,CAAYyB,IAAI,CAACS,MAAL,CAAYG,OAAZ,EAAZ,EAAmCC,SAAnC,EAAT;AAjBC;AAAA,qBAmBgBvC,OAAO,CAACiC,OAAD,EAASnB,KAAT,kCACnBC,OADmB;AAEtBa,gBAAAA,KAAK,EAAE,QAFe;AAGtBY,gBAAAA,OAAO,EAAElC,SAAS,CAACmC,IAHG;AAItBC,gBAAAA,UAAU,EAAE3B,OAAO,CAAC2B;AAJE,iBAnBvB;;AAAA;AAmBDhB,cAAAA,IAAI,CAACC,GAnBJ;AAyBDD,cAAAA,IAAI,CAACiB,IAAL,GAAYV,OAAM,CAACT,MAAnB;;AAzBC;AAAA,gDA4BI;AACLG,gBAAAA,GAAG,EAAED,IAAI,CAACC,GADL;AAELiB,gBAAAA,IAAI,EAAEhC,IAAI,CAACgC,IAFN;AAGLT,gBAAAA,MAAM,EAAET,IAAI,CAACS,MAHR;AAILQ,gBAAAA,IAAI,EAAEjB,IAAI,CAACiB;AAJN,eA5BJ;;AAAA;AAoCL;AACME,cAAAA,CArCD,GAqCK,IAAI9C,MAAJ,CAAW;AACnBqC,gBAAAA,IAAI,EAAE,MADa;AAEnBP,gBAAAA,KAAK,EAAEjB,IAAI,CAACiB,KAFO;AAGnBE,gBAAAA,IAAI,EAAEnB,IAAI,CAACmB;AAHQ,eAAX,CArCL;AA2CCe,cAAAA,KA3CD,GA2CSvB,MAAM,CACjBwB,MADW,CACJ,UAAArB,IAAI,EAAI;AACd,oBAAIA,IAAI,CAACC,GAAL,CAASC,KAAT,KAAmB,KAAnB,IAA4BF,IAAI,CAACiB,IAArC,EAA2C;AACzC,yBAAO,IAAP;AACD;;AAED,oBAAI,CAACjB,IAAI,CAACS,MAAL,CAAYD,IAAb,IAAqBR,IAAI,CAACS,MAAL,CAAYa,QAAZ,EAAzB,EAAiD;AAC/C,yBAAO,IAAP;AACD;;AAED,uBAAOC,OAAO,CAACvB,IAAI,CAACS,MAAL,CAAYD,IAAZ,CAAiBV,MAAlB,CAAd;AACD,eAXW,EAYX0B,GAZW,CAYP,UAACxB,IAAD,EAAU;AACb,oBAAIA,IAAI,CAACC,GAAL,CAASC,KAAT,KAAmB,KAAvB,EAA8B;AAC5B;AACAiB,kBAAAA,CAAC,CAACM,YAAF,CAAezB,IAAI,CAACiB,IAApB;AAEA,yBAAO,IAAIzC,OAAJ,CAAYwB,IAAI,CAACe,IAAjB,EAAuBf,IAAI,CAACiB,IAA5B,EAAkCjB,IAAI,CAACC,GAAvC,CAAP;AACD;;AAED,oBAAI,CAACD,IAAI,CAACS,MAAL,CAAYD,IAAjB,EAAuB;AACrB;AACAW,kBAAAA,CAAC,CAACM,YAAF,CAAezB,IAAI,CAACS,MAAL,CAAYa,QAAZ,EAAf;AACD,iBAHD,MAGO;AACL;AACAH,kBAAAA,CAAC,CAACM,YAAF,CAAezB,IAAI,CAACS,MAAL,CAAYD,IAAZ,CAAiBV,MAAhC;AACD;;AAED,uBAAO,IAAItB,OAAJ,CAAYwB,IAAI,CAACe,IAAjB,EAAuBf,IAAI,CAACiB,IAA5B,EAAkCjB,IAAI,CAACC,GAAvC,CAAP;AACD,eA7BW,CA3CT;AA0ECyB,cAAAA,IA1ED,GA0EQ,IAAInD,OAAJ,CAAY4C,CAAC,CAACP,OAAF,EAAZ,EAAyBQ,KAAzB,CA1ER;AA2ECb,cAAAA,MA3ED,GA2EUmB,IAAI,CAACb,SAAL,EA3EV;AAAA;AAAA,qBA4EavC,OAAO,CAACiC,MAAD,EAASnB,KAAT,EAAgBC,OAAhB,CA5EpB;;AAAA;AA4ECY,cAAAA,GA5ED;AAAA,gDA8EE;AACLA,gBAAAA,GAAG,EAAHA,GADK;AAELiB,gBAAAA,IAAI,EAAEhC,IAAI,CAACgC,IAFN;AAGLT,gBAAAA,MAAM,EAAEU,CAHH;AAILF,gBAAAA,IAAI,EAAEV,MAAM,CAACT,MAAP,GAAgB4B,IAAI,CAACC,KAAL,CAAW/B,MAAX,CAAkB,UAACgC,GAAD,EAAMC,IAAN;AAAA,yBAAeD,GAAG,GAAGC,IAAI,CAACC,KAA1B;AAAA,iBAAlB,EAAmD,CAAnD;AAJjB,eA9EF;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAAP;;AAAA;AAAA;AAAA;AAAA;AAqFD,CAtFD;;AAwFA,IAAMC,WAAW;AAAA,uEAAG,kBAAO7C,IAAP,EAAaC,MAAb,EAAqBC,KAArB,EAA4BC,OAA5B;AAAA;AAAA;AAAA;AAAA;AAAA;AACZ2C,YAAAA,UADY,GACCnD,WAAW,CAACQ,OAAO,CAAC4C,QAAT,CADZ;;AAAA,gBAGbD,UAHa;AAAA;AAAA;AAAA;;AAAA,kBAIV7D,OAAO,CAAC,IAAI+D,KAAJ,iDAAmD7C,OAAO,CAAC4C,QAA3D,EAAD,EAAyE,kBAAzE,CAJG;;AAAA;AAAA;AAAA,mBAOExD,GAAG,CAACuD,UAAU,CAAC/C,cAAc,CAACC,IAAD,EAAOC,MAAP,EAAeC,KAAf,EAAsBC,OAAtB,CAAf,EAA+CO,MAAM,CAACV,IAAD,EAAOE,KAAP,EAAcC,OAAd,CAArD,EAA6EA,OAA7E,CAAX,CAPL;;AAAA;AAOZ8C,YAAAA,KAPY;;AAAA,kBASdA,KAAK,CAACrC,MAAN,GAAe,CATD;AAAA;AAAA;AAAA;;AAAA,kBAUV3B,OAAO,CAAC,IAAI+D,KAAJ,CAAU,2CAA2CC,KAAK,CAACrC,MAA3D,CAAD,EAAqE,eAArE,CAVG;;AAAA;AAAA,8CAaXqC,KAAK,CAAC,CAAD,CAbM;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAAH;;AAAA,kBAAXJ,WAAW;AAAA;AAAA;AAAA,GAAjB;;AAgBAK,MAAM,CAACC,OAAP,GAAiBN,WAAjB","sourcesContent":["'use strict'\n\nconst errCode = require('err-code')\nconst UnixFS = require('ipfs-unixfs')\nconst persist = require('../../utils/persist')\nconst {\n  DAGNode,\n  DAGLink\n} = require('ipld-dag-pb')\nconst all = require('it-all')\nconst parallelBatch = require('it-parallel-batch')\nconst mh = require('multihashing-async').multihash\n\nconst dagBuilders = {\n  flat: require('./flat'),\n  balanced: require('./balanced'),\n  trickle: require('./trickle')\n}\n\nasync function * buildFileBatch (file, source, block, options) {\n  let count = -1\n  let previous\n  let bufferImporter\n\n  if (typeof options.bufferImporter === 'function') {\n    bufferImporter = options.bufferImporter\n  } else {\n    bufferImporter = require('./buffer-importer')\n  }\n\n  for await (const entry of parallelBatch(bufferImporter(file, source, block, options), options.blockWriteConcurrency)) {\n    count++\n\n    if (count === 0) {\n      previous = entry\n      continue\n    } else if (count === 1) {\n      yield previous\n      previous = null\n    }\n\n    yield entry\n  }\n\n  if (previous) {\n    previous.single = true\n    yield previous\n  }\n}\n\nconst reduce = (file, block, options) => {\n  return async function (leaves) {\n    if (leaves.length === 1 && leaves[0].single && options.reduceSingleLeafToSelf) {\n      const leaf = leaves[0]\n\n      if (leaf.cid.codec === 'raw' && (file.mtime !== undefined || file.mode !== undefined)) {\n        // only one leaf node which is a buffer - we have metadata so convert it into a\n        // UnixFS entry otherwise we'll have nowhere to store the metadata\n        let { data: buffer } = await block.get(leaf.cid, options)\n\n        leaf.unixfs = new UnixFS({\n          type: 'file',\n          mtime: file.mtime,\n          mode: file.mode,\n          data: buffer\n        })\n\n        const multihash = mh.decode(leaf.cid.multihash)\n        buffer = new DAGNode(leaf.unixfs.marshal()).serialize()\n\n        leaf.cid = await persist(buffer, block, {\n          ...options,\n          codec: 'dag-pb',\n          hashAlg: multihash.name,\n          cidVersion: options.cidVersion\n        })\n        leaf.size = buffer.length\n      }\n\n      return {\n        cid: leaf.cid,\n        path: file.path,\n        unixfs: leaf.unixfs,\n        size: leaf.size\n      }\n    }\n\n    // create a parent node and add all the leaves\n    const f = new UnixFS({\n      type: 'file',\n      mtime: file.mtime,\n      mode: file.mode\n    })\n\n    const links = leaves\n      .filter(leaf => {\n        if (leaf.cid.codec === 'raw' && leaf.size) {\n          return true\n        }\n\n        if (!leaf.unixfs.data && leaf.unixfs.fileSize()) {\n          return true\n        }\n\n        return Boolean(leaf.unixfs.data.length)\n      })\n      .map((leaf) => {\n        if (leaf.cid.codec === 'raw') {\n          // node is a leaf buffer\n          f.addBlockSize(leaf.size)\n\n          return new DAGLink(leaf.name, leaf.size, leaf.cid)\n        }\n\n        if (!leaf.unixfs.data) {\n          // node is an intermediate node\n          f.addBlockSize(leaf.unixfs.fileSize())\n        } else {\n          // node is a unixfs 'file' leaf node\n          f.addBlockSize(leaf.unixfs.data.length)\n        }\n\n        return new DAGLink(leaf.name, leaf.size, leaf.cid)\n      })\n\n    const node = new DAGNode(f.marshal(), links)\n    const buffer = node.serialize()\n    const cid = await persist(buffer, block, options)\n\n    return {\n      cid,\n      path: file.path,\n      unixfs: f,\n      size: buffer.length + node.Links.reduce((acc, curr) => acc + curr.Tsize, 0)\n    }\n  }\n}\n\nconst fileBuilder = async (file, source, block, options) => {\n  const dagBuilder = dagBuilders[options.strategy]\n\n  if (!dagBuilder) {\n    throw errCode(new Error(`Unknown importer build strategy name: ${options.strategy}`), 'ERR_BAD_STRATEGY')\n  }\n\n  const roots = await all(dagBuilder(buildFileBatch(file, source, block, options), reduce(file, block, options), options))\n\n  if (roots.length > 1) {\n    throw errCode(new Error('expected a maximum of 1 roots and got ' + roots.length), 'ETOOMANYROOTS')\n  }\n\n  return roots[0]\n}\n\nmodule.exports = fileBuilder\n"]},"metadata":{},"sourceType":"script"}