{"ast":null,"code":"'use strict';\n\nconst parallelBatch = require('it-parallel-batch');\n\nconst mergeOptions = require('merge-options').bind({\n  ignoreUndefined: true\n});\n\nconst defaultOptions = {\n  chunker: 'fixed',\n  strategy: 'balanced',\n  // 'flat', 'trickle'\n  rawLeaves: false,\n  onlyHash: false,\n  reduceSingleLeafToSelf: true,\n  codec: 'dag-pb',\n  hashAlg: 'sha2-256',\n  leafType: 'file',\n  // 'raw'\n  cidVersion: 0,\n  progress: () => () => {},\n  shardSplitThreshold: 1000,\n  fileImportConcurrency: 50,\n  blockWriteConcurrency: 10,\n  minChunkSize: 262144,\n  maxChunkSize: 262144,\n  avgChunkSize: 262144,\n  window: 16,\n  polynomial: 17437180132763653,\n  // https://github.com/ipfs/go-ipfs-chunker/blob/d0125832512163708c0804a3cda060e21acddae4/rabin.go#L11\n  maxChildrenPerNode: 174,\n  layerRepeat: 4,\n  wrapWithDirectory: false,\n  pin: false,\n  recursive: false,\n  hidden: false,\n  preload: false,\n  chunkValidator: null,\n  importBuffer: null\n};\n\nmodule.exports = async function* (source, block, options = {}) {\n  const opts = mergeOptions(defaultOptions, options);\n\n  if (options.cidVersion > 0 && options.rawLeaves === undefined) {\n    // if the cid version is 1 or above, use raw leaves as this is\n    // what go does.\n    opts.rawLeaves = true;\n  }\n\n  if (options.hashAlg !== undefined && options.rawLeaves === undefined) {\n    // if a non-default hash alg has been specified, use raw leaves as this is\n    // what go does.\n    opts.rawLeaves = true;\n  } // go-ifps trickle dag defaults to unixfs raw leaves, balanced dag defaults to file leaves\n\n\n  if (options.strategy === 'trickle') {\n    opts.leafType = 'raw';\n    opts.reduceSingleLeafToSelf = false;\n  }\n\n  if (options.format) {\n    opts.codec = options.format;\n  }\n\n  let dagBuilder;\n\n  if (typeof options.dagBuilder === 'function') {\n    dagBuilder = options.dagBuilder;\n  } else {\n    dagBuilder = require('./dag-builder');\n  }\n\n  let treeBuilder;\n\n  if (typeof options.treeBuilder === 'function') {\n    treeBuilder = options.treeBuilder;\n  } else {\n    treeBuilder = require('./tree-builder');\n  }\n\n  for await (const entry of treeBuilder(parallelBatch(dagBuilder(source, block, opts), opts.fileImportConcurrency), block, opts)) {\n    yield {\n      cid: entry.cid,\n      path: entry.path,\n      unixfs: entry.unixfs,\n      size: entry.size\n    };\n  }\n};","map":{"version":3,"sources":["/Users/yenerkaraca/Documents/GitHub/eth-app/node_modules/ipfs-unixfs-importer/src/index.js"],"names":["parallelBatch","require","mergeOptions","bind","ignoreUndefined","defaultOptions","chunker","strategy","rawLeaves","onlyHash","reduceSingleLeafToSelf","codec","hashAlg","leafType","cidVersion","progress","shardSplitThreshold","fileImportConcurrency","blockWriteConcurrency","minChunkSize","maxChunkSize","avgChunkSize","window","polynomial","maxChildrenPerNode","layerRepeat","wrapWithDirectory","pin","recursive","hidden","preload","chunkValidator","importBuffer","module","exports","source","block","options","opts","undefined","format","dagBuilder","treeBuilder","entry","cid","path","unixfs","size"],"mappings":"AAAA;;AAEA,MAAMA,aAAa,GAAGC,OAAO,CAAC,mBAAD,CAA7B;;AACA,MAAMC,YAAY,GAAGD,OAAO,CAAC,eAAD,CAAP,CAAyBE,IAAzB,CAA8B;AAAEC,EAAAA,eAAe,EAAE;AAAnB,CAA9B,CAArB;;AAEA,MAAMC,cAAc,GAAG;AACrBC,EAAAA,OAAO,EAAE,OADY;AAErBC,EAAAA,QAAQ,EAAE,UAFW;AAEC;AACtBC,EAAAA,SAAS,EAAE,KAHU;AAIrBC,EAAAA,QAAQ,EAAE,KAJW;AAKrBC,EAAAA,sBAAsB,EAAE,IALH;AAMrBC,EAAAA,KAAK,EAAE,QANc;AAOrBC,EAAAA,OAAO,EAAE,UAPY;AAQrBC,EAAAA,QAAQ,EAAE,MARW;AAQH;AAClBC,EAAAA,UAAU,EAAE,CATS;AAUrBC,EAAAA,QAAQ,EAAE,MAAM,MAAM,CAAE,CAVH;AAWrBC,EAAAA,mBAAmB,EAAE,IAXA;AAYrBC,EAAAA,qBAAqB,EAAE,EAZF;AAarBC,EAAAA,qBAAqB,EAAE,EAbF;AAcrBC,EAAAA,YAAY,EAAE,MAdO;AAerBC,EAAAA,YAAY,EAAE,MAfO;AAgBrBC,EAAAA,YAAY,EAAE,MAhBO;AAiBrBC,EAAAA,MAAM,EAAE,EAjBa;AAkBrBC,EAAAA,UAAU,EAAE,iBAlBS;AAkBU;AAC/BC,EAAAA,kBAAkB,EAAE,GAnBC;AAoBrBC,EAAAA,WAAW,EAAE,CApBQ;AAqBrBC,EAAAA,iBAAiB,EAAE,KArBE;AAsBrBC,EAAAA,GAAG,EAAE,KAtBgB;AAuBrBC,EAAAA,SAAS,EAAE,KAvBU;AAwBrBC,EAAAA,MAAM,EAAE,KAxBa;AAyBrBC,EAAAA,OAAO,EAAE,KAzBY;AA0BrBC,EAAAA,cAAc,EAAE,IA1BK;AA2BrBC,EAAAA,YAAY,EAAE;AA3BO,CAAvB;;AA8BAC,MAAM,CAACC,OAAP,GAAiB,iBAAkBC,MAAlB,EAA0BC,KAA1B,EAAiCC,OAAO,GAAG,EAA3C,EAA+C;AAC9D,QAAMC,IAAI,GAAGpC,YAAY,CAACG,cAAD,EAAiBgC,OAAjB,CAAzB;;AAEA,MAAIA,OAAO,CAACvB,UAAR,GAAqB,CAArB,IAA0BuB,OAAO,CAAC7B,SAAR,KAAsB+B,SAApD,EAA+D;AAC7D;AACA;AACAD,IAAAA,IAAI,CAAC9B,SAAL,GAAiB,IAAjB;AACD;;AAED,MAAI6B,OAAO,CAACzB,OAAR,KAAoB2B,SAApB,IAAiCF,OAAO,CAAC7B,SAAR,KAAsB+B,SAA3D,EAAsE;AACpE;AACA;AACAD,IAAAA,IAAI,CAAC9B,SAAL,GAAiB,IAAjB;AACD,GAb6D,CAe9D;;;AACA,MAAI6B,OAAO,CAAC9B,QAAR,KAAqB,SAAzB,EAAoC;AAClC+B,IAAAA,IAAI,CAACzB,QAAL,GAAgB,KAAhB;AACAyB,IAAAA,IAAI,CAAC5B,sBAAL,GAA8B,KAA9B;AACD;;AAED,MAAI2B,OAAO,CAACG,MAAZ,EAAoB;AAClBF,IAAAA,IAAI,CAAC3B,KAAL,GAAa0B,OAAO,CAACG,MAArB;AACD;;AAED,MAAIC,UAAJ;;AAEA,MAAI,OAAOJ,OAAO,CAACI,UAAf,KAA8B,UAAlC,EAA8C;AAC5CA,IAAAA,UAAU,GAAGJ,OAAO,CAACI,UAArB;AACD,GAFD,MAEO;AACLA,IAAAA,UAAU,GAAGxC,OAAO,CAAC,eAAD,CAApB;AACD;;AAED,MAAIyC,WAAJ;;AAEA,MAAI,OAAOL,OAAO,CAACK,WAAf,KAA+B,UAAnC,EAA+C;AAC7CA,IAAAA,WAAW,GAAGL,OAAO,CAACK,WAAtB;AACD,GAFD,MAEO;AACLA,IAAAA,WAAW,GAAGzC,OAAO,CAAC,gBAAD,CAArB;AACD;;AAED,aAAW,MAAM0C,KAAjB,IAA0BD,WAAW,CAAC1C,aAAa,CAACyC,UAAU,CAACN,MAAD,EAASC,KAAT,EAAgBE,IAAhB,CAAX,EAAkCA,IAAI,CAACrB,qBAAvC,CAAd,EAA6EmB,KAA7E,EAAoFE,IAApF,CAArC,EAAgI;AAC9H,UAAM;AACJM,MAAAA,GAAG,EAAED,KAAK,CAACC,GADP;AAEJC,MAAAA,IAAI,EAAEF,KAAK,CAACE,IAFR;AAGJC,MAAAA,MAAM,EAAEH,KAAK,CAACG,MAHV;AAIJC,MAAAA,IAAI,EAAEJ,KAAK,CAACI;AAJR,KAAN;AAMD;AACF,CAjDD","sourcesContent":["'use strict'\n\nconst parallelBatch = require('it-parallel-batch')\nconst mergeOptions = require('merge-options').bind({ ignoreUndefined: true })\n\nconst defaultOptions = {\n  chunker: 'fixed',\n  strategy: 'balanced', // 'flat', 'trickle'\n  rawLeaves: false,\n  onlyHash: false,\n  reduceSingleLeafToSelf: true,\n  codec: 'dag-pb',\n  hashAlg: 'sha2-256',\n  leafType: 'file', // 'raw'\n  cidVersion: 0,\n  progress: () => () => {},\n  shardSplitThreshold: 1000,\n  fileImportConcurrency: 50,\n  blockWriteConcurrency: 10,\n  minChunkSize: 262144,\n  maxChunkSize: 262144,\n  avgChunkSize: 262144,\n  window: 16,\n  polynomial: 17437180132763653, // https://github.com/ipfs/go-ipfs-chunker/blob/d0125832512163708c0804a3cda060e21acddae4/rabin.go#L11\n  maxChildrenPerNode: 174,\n  layerRepeat: 4,\n  wrapWithDirectory: false,\n  pin: false,\n  recursive: false,\n  hidden: false,\n  preload: false,\n  chunkValidator: null,\n  importBuffer: null\n}\n\nmodule.exports = async function * (source, block, options = {}) {\n  const opts = mergeOptions(defaultOptions, options)\n\n  if (options.cidVersion > 0 && options.rawLeaves === undefined) {\n    // if the cid version is 1 or above, use raw leaves as this is\n    // what go does.\n    opts.rawLeaves = true\n  }\n\n  if (options.hashAlg !== undefined && options.rawLeaves === undefined) {\n    // if a non-default hash alg has been specified, use raw leaves as this is\n    // what go does.\n    opts.rawLeaves = true\n  }\n\n  // go-ifps trickle dag defaults to unixfs raw leaves, balanced dag defaults to file leaves\n  if (options.strategy === 'trickle') {\n    opts.leafType = 'raw'\n    opts.reduceSingleLeafToSelf = false\n  }\n\n  if (options.format) {\n    opts.codec = options.format\n  }\n\n  let dagBuilder\n\n  if (typeof options.dagBuilder === 'function') {\n    dagBuilder = options.dagBuilder\n  } else {\n    dagBuilder = require('./dag-builder')\n  }\n\n  let treeBuilder\n\n  if (typeof options.treeBuilder === 'function') {\n    treeBuilder = options.treeBuilder\n  } else {\n    treeBuilder = require('./tree-builder')\n  }\n\n  for await (const entry of treeBuilder(parallelBatch(dagBuilder(source, block, opts), opts.fileImportConcurrency), block, opts)) {\n    yield {\n      cid: entry.cid,\n      path: entry.path,\n      unixfs: entry.unixfs,\n      size: entry.size\n    }\n  }\n}\n"]},"metadata":{},"sourceType":"script"}