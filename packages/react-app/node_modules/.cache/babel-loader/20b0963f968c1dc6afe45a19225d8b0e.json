{"ast":null,"code":"'use strict';\n\nvar _classCallCheck = require(\"/Users/yenerkaraca/Documents/GitHub/eth-app/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/classCallCheck\");\n\nvar _createClass = require(\"/Users/yenerkaraca/Documents/GitHub/eth-app/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/createClass\");\n\nvar _inherits = require(\"/Users/yenerkaraca/Documents/GitHub/eth-app/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/inherits\");\n\nvar _createSuper = require(\"/Users/yenerkaraca/Documents/GitHub/eth-app/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/createSuper\");\n\nvar _regeneratorRuntime = require(\"/Users/yenerkaraca/Documents/GitHub/eth-app/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\");\n\nvar _asyncToGenerator = require(\"/Users/yenerkaraca/Documents/GitHub/eth-app/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/asyncToGenerator\");\n\nvar _awaitAsyncGenerator = require(\"/Users/yenerkaraca/Documents/GitHub/eth-app/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/awaitAsyncGenerator\");\n\nvar _wrapAsyncGenerator = require(\"/Users/yenerkaraca/Documents/GitHub/eth-app/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/wrapAsyncGenerator\");\n\nvar _asyncIterator = require(\"/Users/yenerkaraca/Documents/GitHub/eth-app/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/asyncIterator\");\n\nvar _require = require('ipld-dag-pb'),\n    DAGLink = _require.DAGLink,\n    DAGNode = _require.DAGNode;\n\nvar _require2 = require('buffer'),\n    Buffer = _require2.Buffer;\n\nvar UnixFS = require('ipfs-unixfs');\n\nvar multihashing = require('multihashing-async');\n\nvar Dir = require('./dir');\n\nvar persist = require('./utils/persist');\n\nvar Bucket = require('hamt-sharding');\n\nvar mergeOptions = require('merge-options').bind({\n  ignoreUndefined: true\n});\n\nvar hashFn = /*#__PURE__*/function () {\n  var _ref = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee(value) {\n    var hash, justHash, length, result, i;\n    return _regeneratorRuntime.wrap(function _callee$(_context) {\n      while (1) {\n        switch (_context.prev = _context.next) {\n          case 0:\n            _context.next = 2;\n            return multihashing(Buffer.from(value, 'utf8'), 'murmur3-128');\n\n          case 2:\n            hash = _context.sent;\n            // Multihashing inserts preamble of 2 bytes. Remove it.\n            // Also, murmur3 outputs 128 bit but, accidently, IPFS Go's\n            // implementation only uses the first 64, so we must do the same\n            // for parity..\n            justHash = hash.slice(2, 10);\n            length = justHash.length;\n            result = Buffer.alloc(length); // TODO: invert buffer because that's how Go impl does it\n\n            for (i = 0; i < length; i++) {\n              result[length - i - 1] = justHash[i];\n            }\n\n            return _context.abrupt(\"return\", result);\n\n          case 8:\n          case \"end\":\n            return _context.stop();\n        }\n      }\n    }, _callee);\n  }));\n\n  return function hashFn(_x6) {\n    return _ref.apply(this, arguments);\n  };\n}();\n\nhashFn.code = 0x22; // TODO: get this from multihashing-async?\n\nvar defaultOptions = {\n  hamtHashFn: hashFn,\n  hamtBucketBits: 8\n};\n\nvar DirSharded = /*#__PURE__*/function (_Dir) {\n  _inherits(DirSharded, _Dir);\n\n  var _super = _createSuper(DirSharded);\n\n  function DirSharded(props, options) {\n    var _this3;\n\n    _classCallCheck(this, DirSharded);\n\n    options = mergeOptions(defaultOptions, options);\n    _this3 = _super.call(this, props, options);\n    _this3._bucket = Bucket({\n      hashFn: options.hamtHashFn,\n      bits: options.hamtBucketBits\n    });\n    return _this3;\n  }\n\n  _createClass(DirSharded, [{\n    key: \"put\",\n    value: function () {\n      var _put = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2(name, value) {\n        return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n          while (1) {\n            switch (_context2.prev = _context2.next) {\n              case 0:\n                _context2.next = 2;\n                return this._bucket.put(name, value);\n\n              case 2:\n              case \"end\":\n                return _context2.stop();\n            }\n          }\n        }, _callee2, this);\n      }));\n\n      function put(_x7, _x8) {\n        return _put.apply(this, arguments);\n      }\n\n      return put;\n    }()\n  }, {\n    key: \"get\",\n    value: function get(name) {\n      return this._bucket.get(name);\n    }\n  }, {\n    key: \"childCount\",\n    value: function childCount() {\n      return this._bucket.leafCount();\n    }\n  }, {\n    key: \"directChildrenCount\",\n    value: function directChildrenCount() {\n      return this._bucket.childrenCount();\n    }\n  }, {\n    key: \"onlyChild\",\n    value: function onlyChild() {\n      return this._bucket.onlyChild();\n    }\n  }, {\n    key: \"eachChildSeries\",\n    value: function eachChildSeries() {\n      var _this = this;\n\n      return _wrapAsyncGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3() {\n        var _iteratorNormalCompletion, _didIteratorError, _iteratorError, _iterator, _step, _value, _value5, key, value;\n\n        return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n          while (1) {\n            switch (_context3.prev = _context3.next) {\n              case 0:\n                _iteratorNormalCompletion = true;\n                _didIteratorError = false;\n                _context3.prev = 2;\n                _iterator = _asyncIterator(_this._bucket.eachLeafSeries());\n\n              case 4:\n                _context3.next = 6;\n                return _awaitAsyncGenerator(_iterator.next());\n\n              case 6:\n                _step = _context3.sent;\n                _iteratorNormalCompletion = _step.done;\n                _context3.next = 10;\n                return _awaitAsyncGenerator(_step.value);\n\n              case 10:\n                _value = _context3.sent;\n\n                if (_iteratorNormalCompletion) {\n                  _context3.next = 18;\n                  break;\n                }\n\n                _value5 = _value, key = _value5.key, value = _value5.value;\n                _context3.next = 15;\n                return {\n                  key: key,\n                  child: value\n                };\n\n              case 15:\n                _iteratorNormalCompletion = true;\n                _context3.next = 4;\n                break;\n\n              case 18:\n                _context3.next = 24;\n                break;\n\n              case 20:\n                _context3.prev = 20;\n                _context3.t0 = _context3[\"catch\"](2);\n                _didIteratorError = true;\n                _iteratorError = _context3.t0;\n\n              case 24:\n                _context3.prev = 24;\n                _context3.prev = 25;\n\n                if (!(!_iteratorNormalCompletion && _iterator.return != null)) {\n                  _context3.next = 29;\n                  break;\n                }\n\n                _context3.next = 29;\n                return _awaitAsyncGenerator(_iterator.return());\n\n              case 29:\n                _context3.prev = 29;\n\n                if (!_didIteratorError) {\n                  _context3.next = 32;\n                  break;\n                }\n\n                throw _iteratorError;\n\n              case 32:\n                return _context3.finish(29);\n\n              case 33:\n                return _context3.finish(24);\n\n              case 34:\n              case \"end\":\n                return _context3.stop();\n            }\n          }\n        }, _callee3, null, [[2, 20, 24, 34], [25,, 29, 33]]);\n      }))();\n    }\n  }, {\n    key: \"flush\",\n    value: function flush(path, block) {\n      var _this2 = this;\n\n      return _wrapAsyncGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee4() {\n        var _iteratorNormalCompletion2, _didIteratorError2, _iteratorError2, _iterator2, _step2, _value2, entry;\n\n        return _regeneratorRuntime.wrap(function _callee4$(_context4) {\n          while (1) {\n            switch (_context4.prev = _context4.next) {\n              case 0:\n                _iteratorNormalCompletion2 = true;\n                _didIteratorError2 = false;\n                _context4.prev = 2;\n                _iterator2 = _asyncIterator(_flush2(path, _this2._bucket, block, _this2, _this2.options));\n\n              case 4:\n                _context4.next = 6;\n                return _awaitAsyncGenerator(_iterator2.next());\n\n              case 6:\n                _step2 = _context4.sent;\n                _iteratorNormalCompletion2 = _step2.done;\n                _context4.next = 10;\n                return _awaitAsyncGenerator(_step2.value);\n\n              case 10:\n                _value2 = _context4.sent;\n\n                if (_iteratorNormalCompletion2) {\n                  _context4.next = 18;\n                  break;\n                }\n\n                entry = _value2;\n                _context4.next = 15;\n                return entry;\n\n              case 15:\n                _iteratorNormalCompletion2 = true;\n                _context4.next = 4;\n                break;\n\n              case 18:\n                _context4.next = 24;\n                break;\n\n              case 20:\n                _context4.prev = 20;\n                _context4.t0 = _context4[\"catch\"](2);\n                _didIteratorError2 = true;\n                _iteratorError2 = _context4.t0;\n\n              case 24:\n                _context4.prev = 24;\n                _context4.prev = 25;\n\n                if (!(!_iteratorNormalCompletion2 && _iterator2.return != null)) {\n                  _context4.next = 29;\n                  break;\n                }\n\n                _context4.next = 29;\n                return _awaitAsyncGenerator(_iterator2.return());\n\n              case 29:\n                _context4.prev = 29;\n\n                if (!_didIteratorError2) {\n                  _context4.next = 32;\n                  break;\n                }\n\n                throw _iteratorError2;\n\n              case 32:\n                return _context4.finish(29);\n\n              case 33:\n                return _context4.finish(24);\n\n              case 34:\n              case \"end\":\n                return _context4.stop();\n            }\n          }\n        }, _callee4, null, [[2, 20, 24, 34], [25,, 29, 33]]);\n      }))();\n    }\n  }]);\n\n  return DirSharded;\n}(Dir);\n\nmodule.exports = DirSharded;\nmodule.exports.hashFn = hashFn;\n\nfunction _flush2(_x, _x2, _x3, _x4, _x5) {\n  return _flush.apply(this, arguments);\n}\n\nfunction _flush() {\n  _flush = _wrapAsyncGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee5(path, bucket, block, shardRoot, options) {\n    var children, links, childrenSize, i, child, labelPrefix, shard, _iteratorNormalCompletion3, _didIteratorError3, _iteratorError3, _iterator3, _step3, _value3, subShard, _dir, flushedDir, _iteratorNormalCompletion4, _didIteratorError4, _iteratorError4, _iterator4, _step4, _value4, entry, label, value, _label, _size, data, dir, node, buffer, cid, size;\n\n    return _regeneratorRuntime.wrap(function _callee5$(_context5) {\n      while (1) {\n        switch (_context5.prev = _context5.next) {\n          case 0:\n            children = bucket._children;\n            links = [];\n            childrenSize = 0;\n            i = 0;\n\n          case 4:\n            if (!(i < children.length)) {\n              _context5.next = 105;\n              break;\n            }\n\n            child = children.get(i);\n\n            if (child) {\n              _context5.next = 8;\n              break;\n            }\n\n            return _context5.abrupt(\"continue\", 102);\n\n          case 8:\n            labelPrefix = i.toString(16).toUpperCase().padStart(2, '0');\n\n            if (!Bucket.isBucket(child)) {\n              _context5.next = 52;\n              break;\n            }\n\n            shard = void 0;\n            _iteratorNormalCompletion3 = true;\n            _didIteratorError3 = false;\n            _context5.prev = 13;\n            _context5.t0 = _asyncIterator;\n            _context5.next = 17;\n            return _awaitAsyncGenerator(_flush2('', child, block, null, options));\n\n          case 17:\n            _context5.t1 = _context5.sent;\n            _iterator3 = (0, _context5.t0)(_context5.t1);\n\n          case 19:\n            _context5.next = 21;\n            return _awaitAsyncGenerator(_iterator3.next());\n\n          case 21:\n            _step3 = _context5.sent;\n            _iteratorNormalCompletion3 = _step3.done;\n            _context5.next = 25;\n            return _awaitAsyncGenerator(_step3.value);\n\n          case 25:\n            _value3 = _context5.sent;\n\n            if (_iteratorNormalCompletion3) {\n              _context5.next = 32;\n              break;\n            }\n\n            subShard = _value3;\n            shard = subShard;\n\n          case 29:\n            _iteratorNormalCompletion3 = true;\n            _context5.next = 19;\n            break;\n\n          case 32:\n            _context5.next = 38;\n            break;\n\n          case 34:\n            _context5.prev = 34;\n            _context5.t2 = _context5[\"catch\"](13);\n            _didIteratorError3 = true;\n            _iteratorError3 = _context5.t2;\n\n          case 38:\n            _context5.prev = 38;\n            _context5.prev = 39;\n\n            if (!(!_iteratorNormalCompletion3 && _iterator3.return != null)) {\n              _context5.next = 43;\n              break;\n            }\n\n            _context5.next = 43;\n            return _awaitAsyncGenerator(_iterator3.return());\n\n          case 43:\n            _context5.prev = 43;\n\n            if (!_didIteratorError3) {\n              _context5.next = 46;\n              break;\n            }\n\n            throw _iteratorError3;\n\n          case 46:\n            return _context5.finish(43);\n\n          case 47:\n            return _context5.finish(38);\n\n          case 48:\n            links.push(new DAGLink(labelPrefix, shard.size, shard.cid));\n            childrenSize += shard.size;\n            _context5.next = 102;\n            break;\n\n          case 52:\n            if (!(typeof child.value.flush === 'function')) {\n              _context5.next = 95;\n              break;\n            }\n\n            _dir = child.value;\n            flushedDir = void 0;\n            _iteratorNormalCompletion4 = true;\n            _didIteratorError4 = false;\n            _context5.prev = 57;\n            _iterator4 = _asyncIterator(_dir.flush(_dir.path, block));\n\n          case 59:\n            _context5.next = 61;\n            return _awaitAsyncGenerator(_iterator4.next());\n\n          case 61:\n            _step4 = _context5.sent;\n            _iteratorNormalCompletion4 = _step4.done;\n            _context5.next = 65;\n            return _awaitAsyncGenerator(_step4.value);\n\n          case 65:\n            _value4 = _context5.sent;\n\n            if (_iteratorNormalCompletion4) {\n              _context5.next = 74;\n              break;\n            }\n\n            entry = _value4;\n            flushedDir = entry;\n            _context5.next = 71;\n            return flushedDir;\n\n          case 71:\n            _iteratorNormalCompletion4 = true;\n            _context5.next = 59;\n            break;\n\n          case 74:\n            _context5.next = 80;\n            break;\n\n          case 76:\n            _context5.prev = 76;\n            _context5.t3 = _context5[\"catch\"](57);\n            _didIteratorError4 = true;\n            _iteratorError4 = _context5.t3;\n\n          case 80:\n            _context5.prev = 80;\n            _context5.prev = 81;\n\n            if (!(!_iteratorNormalCompletion4 && _iterator4.return != null)) {\n              _context5.next = 85;\n              break;\n            }\n\n            _context5.next = 85;\n            return _awaitAsyncGenerator(_iterator4.return());\n\n          case 85:\n            _context5.prev = 85;\n\n            if (!_didIteratorError4) {\n              _context5.next = 88;\n              break;\n            }\n\n            throw _iteratorError4;\n\n          case 88:\n            return _context5.finish(85);\n\n          case 89:\n            return _context5.finish(80);\n\n          case 90:\n            label = labelPrefix + child.key;\n            links.push(new DAGLink(label, flushedDir.size, flushedDir.cid));\n            childrenSize += flushedDir.size;\n            _context5.next = 102;\n            break;\n\n          case 95:\n            value = child.value;\n\n            if (value.cid) {\n              _context5.next = 98;\n              break;\n            }\n\n            return _context5.abrupt(\"continue\", 102);\n\n          case 98:\n            _label = labelPrefix + child.key;\n            _size = value.size;\n            links.push(new DAGLink(_label, _size, value.cid));\n            childrenSize += _size;\n\n          case 102:\n            i++;\n            _context5.next = 4;\n            break;\n\n          case 105:\n            // go-ipfs uses little endian, that's why we have to\n            // reverse the bit field before storing it\n            data = Buffer.from(children.bitField().reverse());\n            dir = new UnixFS({\n              type: 'hamt-sharded-directory',\n              data: data,\n              fanout: bucket.tableSize(),\n              hashType: options.hamtHashFn.code,\n              mtime: shardRoot && shardRoot.mtime,\n              mode: shardRoot && shardRoot.mode\n            });\n            node = new DAGNode(dir.marshal(), links);\n            buffer = node.serialize();\n            _context5.next = 111;\n            return _awaitAsyncGenerator(persist(buffer, block, options));\n\n          case 111:\n            cid = _context5.sent;\n            size = buffer.length + childrenSize;\n            _context5.next = 115;\n            return {\n              cid: cid,\n              unixfs: dir,\n              path: path,\n              size: size\n            };\n\n          case 115:\n          case \"end\":\n            return _context5.stop();\n        }\n      }\n    }, _callee5, null, [[13, 34, 38, 48], [39,, 43, 47], [57, 76, 80, 90], [81,, 85, 89]]);\n  }));\n  return _flush.apply(this, arguments);\n}","map":{"version":3,"sources":["/Users/yenerkaraca/Documents/GitHub/eth-app/node_modules/ipfs-unixfs-importer/src/dir-sharded.js"],"names":["require","DAGLink","DAGNode","Buffer","UnixFS","multihashing","Dir","persist","Bucket","mergeOptions","bind","ignoreUndefined","hashFn","value","from","hash","justHash","slice","length","result","alloc","i","code","defaultOptions","hamtHashFn","hamtBucketBits","DirSharded","props","options","_bucket","bits","name","put","get","leafCount","childrenCount","onlyChild","eachLeafSeries","key","child","path","block","flush","entry","module","exports","bucket","shardRoot","children","_children","links","childrenSize","labelPrefix","toString","toUpperCase","padStart","isBucket","shard","subShard","push","size","cid","dir","flushedDir","label","data","bitField","reverse","type","fanout","tableSize","hashType","mtime","mode","node","marshal","buffer","serialize","unixfs"],"mappings":"AAAA;;;;;;;;;;;;;;;;;;;;eAKIA,OAAO,CAAC,aAAD,C;IAFTC,O,YAAAA,O;IACAC,O,YAAAA,O;;gBAEiBF,OAAO,CAAC,QAAD,C;IAAlBG,M,aAAAA,M;;AACR,IAAMC,MAAM,GAAGJ,OAAO,CAAC,aAAD,CAAtB;;AACA,IAAMK,YAAY,GAAGL,OAAO,CAAC,oBAAD,CAA5B;;AACA,IAAMM,GAAG,GAAGN,OAAO,CAAC,OAAD,CAAnB;;AACA,IAAMO,OAAO,GAAGP,OAAO,CAAC,iBAAD,CAAvB;;AACA,IAAMQ,MAAM,GAAGR,OAAO,CAAC,eAAD,CAAtB;;AACA,IAAMS,YAAY,GAAGT,OAAO,CAAC,eAAD,CAAP,CAAyBU,IAAzB,CAA8B;AAAEC,EAAAA,eAAe,EAAE;AAAnB,CAA9B,CAArB;;AAEA,IAAMC,MAAM;AAAA,sEAAG,iBAAgBC,KAAhB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBACMR,YAAY,CAACF,MAAM,CAACW,IAAP,CAAYD,KAAZ,EAAmB,MAAnB,CAAD,EAA6B,aAA7B,CADlB;;AAAA;AACPE,YAAAA,IADO;AAGb;AACA;AACA;AACA;AACMC,YAAAA,QAPO,GAOID,IAAI,CAACE,KAAL,CAAW,CAAX,EAAc,EAAd,CAPJ;AAQPC,YAAAA,MARO,GAQEF,QAAQ,CAACE,MARX;AASPC,YAAAA,MATO,GASEhB,MAAM,CAACiB,KAAP,CAAaF,MAAb,CATF,EAUb;;AACA,iBAASG,CAAT,GAAa,CAAb,EAAgBA,CAAC,GAAGH,MAApB,EAA4BG,CAAC,EAA7B,EAAiC;AAC/BF,cAAAA,MAAM,CAACD,MAAM,GAAGG,CAAT,GAAa,CAAd,CAAN,GAAyBL,QAAQ,CAACK,CAAD,CAAjC;AACD;;AAbY,6CAeNF,MAfM;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAAH;;AAAA,kBAANP,MAAM;AAAA;AAAA;AAAA,GAAZ;;AAiBAA,MAAM,CAACU,IAAP,GAAc,IAAd,C,CAAmB;;AAEnB,IAAMC,cAAc,GAAG;AACrBC,EAAAA,UAAU,EAAEZ,MADS;AAErBa,EAAAA,cAAc,EAAE;AAFK,CAAvB;;IAKMC,U;;;;;AACJ,sBAAaC,KAAb,EAAoBC,OAApB,EAA6B;AAAA;;AAAA;;AAC3BA,IAAAA,OAAO,GAAGnB,YAAY,CAACc,cAAD,EAAiBK,OAAjB,CAAtB;AAEA,+BAAMD,KAAN,EAAaC,OAAb;AAEA,WAAKC,OAAL,GAAerB,MAAM,CAAC;AACpBI,MAAAA,MAAM,EAAEgB,OAAO,CAACJ,UADI;AAEpBM,MAAAA,IAAI,EAAEF,OAAO,CAACH;AAFM,KAAD,CAArB;AAL2B;AAS5B;;;;;4FAEUM,I,EAAMlB,K;;;;;;uBACT,KAAKgB,OAAL,CAAaG,GAAb,CAAiBD,IAAjB,EAAuBlB,KAAvB,C;;;;;;;;;;;;;;;;;;wBAGHkB,I,EAAM;AACT,aAAO,KAAKF,OAAL,CAAaI,GAAb,CAAiBF,IAAjB,CAAP;AACD;;;iCAEa;AACZ,aAAO,KAAKF,OAAL,CAAaK,SAAb,EAAP;AACD;;;0CAEsB;AACrB,aAAO,KAAKL,OAAL,CAAaM,aAAb,EAAP;AACD;;;gCAEY;AACX,aAAO,KAAKN,OAAL,CAAaO,SAAb,EAAP;AACD;;;sCAE0B;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2CACU,KAAI,CAACP,OAAL,CAAaQ,cAAb,EADV;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA,kCACNC,GADM,WACNA,GADM,EACDzB,KADC,WACDA,KADC;AAAA;AAEvB,uBAAM;AACJyB,kBAAAA,GAAG,EAAHA,GADI;AAEJC,kBAAAA,KAAK,EAAE1B;AAFH,iBAAN;;AAFuB;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAO1B;;;0BAEc2B,I,EAAMC,K,EAAO;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4CACAC,OAAK,CAACF,IAAD,EAAO,MAAI,CAACX,OAAZ,EAAqBY,KAArB,EAA4B,MAA5B,EAAkC,MAAI,CAACb,OAAvC,CADL;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AACTe,gBAAAA,KADS;AAAA;AAExB,uBAAMA,KAAN;;AAFwB;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAI3B;;;;EA7CsBrC,G;;AAgDzBsC,MAAM,CAACC,OAAP,GAAiBnB,UAAjB;AAEAkB,MAAM,CAACC,OAAP,CAAejC,MAAf,GAAwBA,MAAxB;;SAEiB8B,O;;;;;sEAAjB,kBAAwBF,IAAxB,EAA8BM,MAA9B,EAAsCL,KAAtC,EAA6CM,SAA7C,EAAwDnB,OAAxD;AAAA;;AAAA;AAAA;AAAA;AAAA;AACQoB,YAAAA,QADR,GACmBF,MAAM,CAACG,SAD1B;AAEQC,YAAAA,KAFR,GAEgB,EAFhB;AAGMC,YAAAA,YAHN,GAGqB,CAHrB;AAKW9B,YAAAA,CALX,GAKe,CALf;;AAAA;AAAA,kBAKkBA,CAAC,GAAG2B,QAAQ,CAAC9B,MAL/B;AAAA;AAAA;AAAA;;AAMUqB,YAAAA,KANV,GAMkBS,QAAQ,CAACf,GAAT,CAAaZ,CAAb,CANlB;;AAAA,gBAQSkB,KART;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAYUa,YAAAA,WAZV,GAYwB/B,CAAC,CAACgC,QAAF,CAAW,EAAX,EAAeC,WAAf,GAA6BC,QAA7B,CAAsC,CAAtC,EAAyC,GAAzC,CAZxB;;AAAA,iBAcQ/C,MAAM,CAACgD,QAAP,CAAgBjB,KAAhB,CAdR;AAAA;AAAA;AAAA;;AAeUkB,YAAAA,KAfV;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wCAiByCf,OAAK,CAAC,EAAD,EAAKH,KAAL,EAAYE,KAAZ,EAAmB,IAAnB,EAAyBb,OAAzB,CAjB9C;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAiBuB8B,YAAAA,QAjBvB;AAkBQD,YAAAA,KAAK,GAAGC,QAAR;;AAlBR;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAqBMR,YAAAA,KAAK,CAACS,IAAN,CAAW,IAAI1D,OAAJ,CAAYmD,WAAZ,EAAyBK,KAAK,CAACG,IAA/B,EAAqCH,KAAK,CAACI,GAA3C,CAAX;AACAV,YAAAA,YAAY,IAAIM,KAAK,CAACG,IAAtB;AAtBN;AAAA;;AAAA;AAAA,kBAuBe,OAAOrB,KAAK,CAAC1B,KAAN,CAAY6B,KAAnB,KAA6B,UAvB5C;AAAA;AAAA;AAAA;;AAwBYoB,YAAAA,IAxBZ,GAwBkBvB,KAAK,CAAC1B,KAxBxB;AAyBUkD,YAAAA,UAzBV;AAAA;AAAA;AAAA;AAAA,wCA2BgCD,IAAG,CAACpB,KAAJ,CAAUoB,IAAG,CAACtB,IAAd,EAAoBC,KAApB,CA3BhC;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AA2BuBE,YAAAA,KA3BvB;AA4BQoB,YAAAA,UAAU,GAAGpB,KAAb;AA5BR;AA8BQ,mBAAMoB,UAAN;;AA9BR;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAiCYC,YAAAA,KAjCZ,GAiCoBZ,WAAW,GAAGb,KAAK,CAACD,GAjCxC;AAkCMY,YAAAA,KAAK,CAACS,IAAN,CAAW,IAAI1D,OAAJ,CAAY+D,KAAZ,EAAmBD,UAAU,CAACH,IAA9B,EAAoCG,UAAU,CAACF,GAA/C,CAAX;AAEAV,YAAAA,YAAY,IAAIY,UAAU,CAACH,IAA3B;AApCN;AAAA;;AAAA;AAsCY/C,YAAAA,KAtCZ,GAsCoB0B,KAAK,CAAC1B,KAtC1B;;AAAA,gBAwCWA,KAAK,CAACgD,GAxCjB;AAAA;AAAA;AAAA;;AAAA;;AAAA;AA4CYG,YAAAA,MA5CZ,GA4CoBZ,WAAW,GAAGb,KAAK,CAACD,GA5CxC;AA6CYsB,YAAAA,KA7CZ,GA6CmB/C,KAAK,CAAC+C,IA7CzB;AA+CMV,YAAAA,KAAK,CAACS,IAAN,CAAW,IAAI1D,OAAJ,CAAY+D,MAAZ,EAAmBJ,KAAnB,EAAyB/C,KAAK,CAACgD,GAA/B,CAAX;AACAV,YAAAA,YAAY,IAAIS,KAAhB;;AAhDN;AAKuCvC,YAAAA,CAAC,EALxC;AAAA;AAAA;;AAAA;AAoDE;AACA;AACM4C,YAAAA,IAtDR,GAsDe9D,MAAM,CAACW,IAAP,CAAYkC,QAAQ,CAACkB,QAAT,GAAoBC,OAApB,EAAZ,CAtDf;AAuDQL,YAAAA,GAvDR,GAuDc,IAAI1D,MAAJ,CAAW;AACrBgE,cAAAA,IAAI,EAAE,wBADe;AAErBH,cAAAA,IAAI,EAAJA,IAFqB;AAGrBI,cAAAA,MAAM,EAAEvB,MAAM,CAACwB,SAAP,EAHa;AAIrBC,cAAAA,QAAQ,EAAE3C,OAAO,CAACJ,UAAR,CAAmBF,IAJR;AAKrBkD,cAAAA,KAAK,EAAEzB,SAAS,IAAIA,SAAS,CAACyB,KALT;AAMrBC,cAAAA,IAAI,EAAE1B,SAAS,IAAIA,SAAS,CAAC0B;AANR,aAAX,CAvDd;AAgEQC,YAAAA,IAhER,GAgEe,IAAIxE,OAAJ,CAAY4D,GAAG,CAACa,OAAJ,EAAZ,EAA2BzB,KAA3B,CAhEf;AAiEQ0B,YAAAA,MAjER,GAiEiBF,IAAI,CAACG,SAAL,EAjEjB;AAAA;AAAA,wCAkEoBtE,OAAO,CAACqE,MAAD,EAASnC,KAAT,EAAgBb,OAAhB,CAlE3B;;AAAA;AAkEQiC,YAAAA,GAlER;AAmEQD,YAAAA,IAnER,GAmEegB,MAAM,CAAC1D,MAAP,GAAgBiC,YAnE/B;AAAA;AAqEE,mBAAM;AACJU,cAAAA,GAAG,EAAHA,GADI;AAEJiB,cAAAA,MAAM,EAAEhB,GAFJ;AAGJtB,cAAAA,IAAI,EAAJA,IAHI;AAIJoB,cAAAA,IAAI,EAAJA;AAJI,aAAN;;AArEF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,G","sourcesContent":["'use strict'\n\nconst {\n  DAGLink,\n  DAGNode\n} = require('ipld-dag-pb')\nconst { Buffer } = require('buffer')\nconst UnixFS = require('ipfs-unixfs')\nconst multihashing = require('multihashing-async')\nconst Dir = require('./dir')\nconst persist = require('./utils/persist')\nconst Bucket = require('hamt-sharding')\nconst mergeOptions = require('merge-options').bind({ ignoreUndefined: true })\n\nconst hashFn = async function (value) {\n  const hash = await multihashing(Buffer.from(value, 'utf8'), 'murmur3-128')\n\n  // Multihashing inserts preamble of 2 bytes. Remove it.\n  // Also, murmur3 outputs 128 bit but, accidently, IPFS Go's\n  // implementation only uses the first 64, so we must do the same\n  // for parity..\n  const justHash = hash.slice(2, 10)\n  const length = justHash.length\n  const result = Buffer.alloc(length)\n  // TODO: invert buffer because that's how Go impl does it\n  for (let i = 0; i < length; i++) {\n    result[length - i - 1] = justHash[i]\n  }\n\n  return result\n}\nhashFn.code = 0x22 // TODO: get this from multihashing-async?\n\nconst defaultOptions = {\n  hamtHashFn: hashFn,\n  hamtBucketBits: 8\n}\n\nclass DirSharded extends Dir {\n  constructor (props, options) {\n    options = mergeOptions(defaultOptions, options)\n\n    super(props, options)\n\n    this._bucket = Bucket({\n      hashFn: options.hamtHashFn,\n      bits: options.hamtBucketBits\n    })\n  }\n\n  async put (name, value) {\n    await this._bucket.put(name, value)\n  }\n\n  get (name) {\n    return this._bucket.get(name)\n  }\n\n  childCount () {\n    return this._bucket.leafCount()\n  }\n\n  directChildrenCount () {\n    return this._bucket.childrenCount()\n  }\n\n  onlyChild () {\n    return this._bucket.onlyChild()\n  }\n\n  async * eachChildSeries () {\n    for await (const { key, value } of this._bucket.eachLeafSeries()) {\n      yield {\n        key,\n        child: value\n      }\n    }\n  }\n\n  async * flush (path, block) {\n    for await (const entry of flush(path, this._bucket, block, this, this.options)) {\n      yield entry\n    }\n  }\n}\n\nmodule.exports = DirSharded\n\nmodule.exports.hashFn = hashFn\n\nasync function * flush (path, bucket, block, shardRoot, options) {\n  const children = bucket._children\n  const links = []\n  let childrenSize = 0\n\n  for (let i = 0; i < children.length; i++) {\n    const child = children.get(i)\n\n    if (!child) {\n      continue\n    }\n\n    const labelPrefix = i.toString(16).toUpperCase().padStart(2, '0')\n\n    if (Bucket.isBucket(child)) {\n      let shard\n\n      for await (const subShard of await flush('', child, block, null, options)) {\n        shard = subShard\n      }\n\n      links.push(new DAGLink(labelPrefix, shard.size, shard.cid))\n      childrenSize += shard.size\n    } else if (typeof child.value.flush === 'function') {\n      const dir = child.value\n      let flushedDir\n\n      for await (const entry of dir.flush(dir.path, block)) {\n        flushedDir = entry\n\n        yield flushedDir\n      }\n\n      const label = labelPrefix + child.key\n      links.push(new DAGLink(label, flushedDir.size, flushedDir.cid))\n\n      childrenSize += flushedDir.size\n    } else {\n      const value = child.value\n\n      if (!value.cid) {\n        continue\n      }\n\n      const label = labelPrefix + child.key\n      const size = value.size\n\n      links.push(new DAGLink(label, size, value.cid))\n      childrenSize += size\n    }\n  }\n\n  // go-ipfs uses little endian, that's why we have to\n  // reverse the bit field before storing it\n  const data = Buffer.from(children.bitField().reverse())\n  const dir = new UnixFS({\n    type: 'hamt-sharded-directory',\n    data,\n    fanout: bucket.tableSize(),\n    hashType: options.hamtHashFn.code,\n    mtime: shardRoot && shardRoot.mtime,\n    mode: shardRoot && shardRoot.mode\n  })\n\n  const node = new DAGNode(dir.marshal(), links)\n  const buffer = node.serialize()\n  const cid = await persist(buffer, block, options)\n  const size = buffer.length + childrenSize\n\n  yield {\n    cid,\n    unixfs: dir,\n    path,\n    size\n  }\n}\n"]},"metadata":{},"sourceType":"script"}