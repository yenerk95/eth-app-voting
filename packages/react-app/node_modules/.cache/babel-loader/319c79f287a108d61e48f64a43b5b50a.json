{"ast":null,"code":"'use strict';\n\nvar _regeneratorRuntime = require(\"/Users/yenerkaraca/Documents/GitHub/eth-app/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\");\n\nvar _objectSpread = require(\"/Users/yenerkaraca/Documents/GitHub/eth-app/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/objectSpread2\");\n\nvar _asyncToGenerator = require(\"/Users/yenerkaraca/Documents/GitHub/eth-app/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/asyncToGenerator\");\n\nvar _require = require('ipld-dag-pb'),\n    DAGLink = _require.DAGLink,\n    DAGNode = _require.DAGNode;\n\nvar CID = require('cids');\n\nvar log = require('debug')('ipfs:mfs:core:utils:add-link');\n\nvar UnixFS = require('ipfs-unixfs');\n\nvar DirSharded = require('ipfs-unixfs-importer/src/dir-sharded');\n\nvar _require2 = require('./hamt-utils'),\n    updateHamtDirectory = _require2.updateHamtDirectory,\n    recreateHamtLevel = _require2.recreateHamtLevel,\n    createShard = _require2.createShard,\n    toPrefix = _require2.toPrefix,\n    addLinksToHamtBucket = _require2.addLinksToHamtBucket;\n\nvar errCode = require('err-code');\n\nvar mc = require('multicodec');\n\nvar mh = require('multihashing-async').multihash;\n\nvar last = require('it-last');\n\nvar addLink = /*#__PURE__*/function () {\n  var _ref = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee(context, options) {\n    var meta;\n    return _regeneratorRuntime.wrap(function _callee$(_context) {\n      while (1) {\n        switch (_context.prev = _context.next) {\n          case 0:\n            if (!(!options.parentCid && !options.parent)) {\n              _context.next = 2;\n              break;\n            }\n\n            throw errCode(new Error('No parent node or CID passed to addLink'), 'EINVALIDPARENT');\n\n          case 2:\n            if (!(options.parentCid && !CID.isCID(options.parentCid))) {\n              _context.next = 4;\n              break;\n            }\n\n            throw errCode(new Error('Invalid CID passed to addLink'), 'EINVALIDPARENTCID');\n\n          case 4:\n            if (options.parent) {\n              _context.next = 9;\n              break;\n            }\n\n            log(\"Loading parent node \".concat(options.parentCid));\n            _context.next = 8;\n            return context.ipld.get(options.parentCid);\n\n          case 8:\n            options.parent = _context.sent;\n\n          case 9:\n            if (options.cid) {\n              _context.next = 11;\n              break;\n            }\n\n            throw errCode(new Error('No child cid passed to addLink'), 'EINVALIDCHILDCID');\n\n          case 11:\n            if (options.name) {\n              _context.next = 13;\n              break;\n            }\n\n            throw errCode(new Error('No child name passed to addLink'), 'EINVALIDCHILDNAME');\n\n          case 13:\n            if (!CID.isCID(options.cid)) {\n              options.cid = new CID(options.cid);\n            }\n\n            if (!(!options.size && options.size !== 0)) {\n              _context.next = 16;\n              break;\n            }\n\n            throw errCode(new Error('No child size passed to addLink'), 'EINVALIDCHILDSIZE');\n\n          case 16:\n            meta = UnixFS.unmarshal(options.parent.Data);\n\n            if (!(meta.type === 'hamt-sharded-directory')) {\n              _context.next = 20;\n              break;\n            }\n\n            log('Adding link to sharded directory');\n            return _context.abrupt(\"return\", addToShardedDirectory(context, options));\n\n          case 20:\n            if (!(options.parent.Links.length >= options.shardSplitThreshold)) {\n              _context.next = 23;\n              break;\n            }\n\n            log('Converting directory to sharded directory');\n            return _context.abrupt(\"return\", convertToShardedDirectory(context, _objectSpread(_objectSpread({}, options), {}, {\n              mtime: meta.mtime,\n              mode: meta.mode\n            })));\n\n          case 23:\n            log(\"Adding \".concat(options.name, \" (\").concat(options.cid, \") to regular directory\"));\n            return _context.abrupt(\"return\", addToDirectory(context, options));\n\n          case 25:\n          case \"end\":\n            return _context.stop();\n        }\n      }\n    }, _callee);\n  }));\n\n  return function addLink(_x, _x2) {\n    return _ref.apply(this, arguments);\n  };\n}();\n\nvar convertToShardedDirectory = /*#__PURE__*/function () {\n  var _ref2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2(context, options) {\n    var result;\n    return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n      while (1) {\n        switch (_context2.prev = _context2.next) {\n          case 0:\n            _context2.next = 2;\n            return createShard(context, options.parent.Links.map(function (link) {\n              return {\n                name: link.Name,\n                size: link.Tsize,\n                cid: link.Hash\n              };\n            }).concat({\n              name: options.name,\n              size: options.size,\n              cid: options.cid\n            }), options);\n\n          case 2:\n            result = _context2.sent;\n            log(\"Converted directory to sharded directory \".concat(result.cid));\n            return _context2.abrupt(\"return\", result);\n\n          case 5:\n          case \"end\":\n            return _context2.stop();\n        }\n      }\n    }, _callee2);\n  }));\n\n  return function convertToShardedDirectory(_x3, _x4) {\n    return _ref2.apply(this, arguments);\n  };\n}();\n\nvar addToDirectory = /*#__PURE__*/function () {\n  var _ref3 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3(context, options) {\n    var node, hashAlg, cid;\n    return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n      while (1) {\n        switch (_context3.prev = _context3.next) {\n          case 0:\n            options.parent.rmLink(options.name);\n            options.parent.addLink(new DAGLink(options.name, options.size, options.cid));\n            node = UnixFS.unmarshal(options.parent.Data);\n\n            if (node.mtime) {\n              // Update mtime if previously set\n              node.mtime = new Date();\n              options.parent = new DAGNode(node.marshal(), options.parent.Links);\n            }\n\n            hashAlg = mh.names[options.hashAlg]; // Persist the new parent DAGNode\n\n            _context3.next = 7;\n            return context.ipld.put(options.parent, mc.DAG_PB, {\n              cidVersion: options.cidVersion,\n              hashAlg: hashAlg,\n              onlyHash: !options.flush\n            });\n\n          case 7:\n            cid = _context3.sent;\n            return _context3.abrupt(\"return\", {\n              node: options.parent,\n              cid: cid,\n              size: options.parent.size\n            });\n\n          case 9:\n          case \"end\":\n            return _context3.stop();\n        }\n      }\n    }, _callee3);\n  }));\n\n  return function addToDirectory(_x5, _x6) {\n    return _ref3.apply(this, arguments);\n  };\n}();\n\nvar addToShardedDirectory = /*#__PURE__*/function () {\n  var _ref4 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee4(context, options) {\n    var _yield$addFileToShard, shard, path, result, node, oldLink, newLink;\n\n    return _regeneratorRuntime.wrap(function _callee4$(_context4) {\n      while (1) {\n        switch (_context4.prev = _context4.next) {\n          case 0:\n            _context4.next = 2;\n            return addFileToShardedDirectory(context, options);\n\n          case 2:\n            _yield$addFileToShard = _context4.sent;\n            shard = _yield$addFileToShard.shard;\n            path = _yield$addFileToShard.path;\n            _context4.next = 7;\n            return last(shard.flush('', context.block));\n\n          case 7:\n            result = _context4.sent;\n            _context4.next = 10;\n            return context.ipld.get(result.cid);\n\n          case 10:\n            node = _context4.sent;\n            // we have written out the shard, but only one sub-shard will have been written so replace it in the original shard\n            oldLink = options.parent.Links.find(function (link) {\n              return link.Name.substring(0, 2) === path[0].prefix;\n            });\n            newLink = node.Links.find(function (link) {\n              return link.Name.substring(0, 2) === path[0].prefix;\n            });\n\n            if (oldLink) {\n              options.parent.rmLink(oldLink.Name);\n            }\n\n            options.parent.addLink(newLink);\n            return _context4.abrupt(\"return\", updateHamtDirectory(context, options.parent.Links, path[0].bucket, options));\n\n          case 16:\n          case \"end\":\n            return _context4.stop();\n        }\n      }\n    }, _callee4);\n  }));\n\n  return function addToShardedDirectory(_x7, _x8) {\n    return _ref4.apply(this, arguments);\n  };\n}();\n\nvar addFileToShardedDirectory = /*#__PURE__*/function () {\n  var _ref5 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee5(context, options) {\n    var file, rootBucket, node, shard, position, path, index, _loop, _ret;\n\n    return _regeneratorRuntime.wrap(function _callee5$(_context6) {\n      while (1) {\n        switch (_context6.prev = _context6.next) {\n          case 0:\n            file = {\n              name: options.name,\n              cid: options.cid,\n              size: options.size\n            }; // start at the root bucket and descend, loading nodes as we go\n\n            _context6.next = 3;\n            return recreateHamtLevel(options.parent.Links);\n\n          case 3:\n            rootBucket = _context6.sent;\n            node = UnixFS.unmarshal(options.parent.Data);\n            shard = new DirSharded({\n              root: true,\n              dir: true,\n              parent: null,\n              parentKey: null,\n              path: '',\n              dirty: true,\n              flat: false,\n              mode: node.mode\n            }, options);\n            shard._bucket = rootBucket;\n\n            if (node.mtime) {\n              // update mtime if previously set\n              shard.mtime = new Date();\n            } // load subshards until the bucket & position no longer changes\n\n\n            _context6.next = 10;\n            return rootBucket._findNewBucketAndPos(file.name);\n\n          case 10:\n            position = _context6.sent;\n            path = toBucketPath(position);\n            path[0].node = options.parent;\n            index = 0;\n            _loop = /*#__PURE__*/_regeneratorRuntime.mark(function _loop() {\n              var segment, node, link, subShard, _position, nextSegment;\n\n              return _regeneratorRuntime.wrap(function _loop$(_context5) {\n                while (1) {\n                  switch (_context5.prev = _context5.next) {\n                    case 0:\n                      segment = path[index];\n                      index++;\n                      node = segment.node;\n                      link = node.Links.find(function (link) {\n                        return link.Name.substring(0, 2) === segment.prefix;\n                      });\n\n                      if (link) {\n                        _context5.next = 8;\n                        break;\n                      }\n\n                      // prefix is new, file will be added to the current bucket\n                      log(\"Link \".concat(segment.prefix).concat(file.name, \" will be added\"));\n                      index = path.length;\n                      return _context5.abrupt(\"return\", \"break\");\n\n                    case 8:\n                      if (!(link.Name === \"\".concat(segment.prefix).concat(file.name))) {\n                        _context5.next = 12;\n                        break;\n                      }\n\n                      // file already existed, file will be added to the current bucket\n                      log(\"Link \".concat(segment.prefix).concat(file.name, \" will be replaced\"));\n                      index = path.length;\n                      return _context5.abrupt(\"return\", \"break\");\n\n                    case 12:\n                      if (!(link.Name.length > 2)) {\n                        _context5.next = 16;\n                        break;\n                      }\n\n                      // another file had the same prefix, will be replaced with a subshard\n                      log(\"Link \".concat(link.Name, \" \").concat(link.Hash, \" will be replaced with a subshard\"));\n                      index = path.length;\n                      return _context5.abrupt(\"return\", \"break\");\n\n                    case 16:\n                      // load sub-shard\n                      log(\"Found subshard \".concat(segment.prefix));\n                      _context5.next = 19;\n                      return context.ipld.get(link.Hash);\n\n                    case 19:\n                      subShard = _context5.sent;\n\n                      if (path[index]) {\n                        _context5.next = 29;\n                        break;\n                      }\n\n                      log(\"Loaded new subshard \".concat(segment.prefix));\n                      _context5.next = 24;\n                      return recreateHamtLevel(subShard.Links, rootBucket, segment.bucket, parseInt(segment.prefix, 16));\n\n                    case 24:\n                      _context5.next = 26;\n                      return rootBucket._findNewBucketAndPos(file.name);\n\n                    case 26:\n                      _position = _context5.sent;\n                      path.push({\n                        bucket: _position.bucket,\n                        prefix: toPrefix(_position.pos),\n                        node: subShard\n                      });\n                      return _context5.abrupt(\"return\", \"break\");\n\n                    case 29:\n                      nextSegment = path[index]; // add next levels worth of links to bucket\n\n                      _context5.next = 32;\n                      return addLinksToHamtBucket(subShard.Links, nextSegment.bucket, rootBucket);\n\n                    case 32:\n                      nextSegment.node = subShard;\n\n                    case 33:\n                    case \"end\":\n                      return _context5.stop();\n                  }\n                }\n              }, _loop);\n            });\n\n          case 15:\n            if (!(index < path.length)) {\n              _context6.next = 22;\n              break;\n            }\n\n            return _context6.delegateYield(_loop(), \"t0\", 17);\n\n          case 17:\n            _ret = _context6.t0;\n\n            if (!(_ret === \"break\")) {\n              _context6.next = 20;\n              break;\n            }\n\n            return _context6.abrupt(\"break\", 22);\n\n          case 20:\n            _context6.next = 15;\n            break;\n\n          case 22:\n            _context6.next = 24;\n            return shard._bucket.put(file.name, {\n              size: file.size,\n              cid: file.cid\n            });\n\n          case 24:\n            return _context6.abrupt(\"return\", {\n              shard: shard,\n              path: path\n            });\n\n          case 25:\n          case \"end\":\n            return _context6.stop();\n        }\n      }\n    }, _callee5);\n  }));\n\n  return function addFileToShardedDirectory(_x9, _x10) {\n    return _ref5.apply(this, arguments);\n  };\n}();\n\nvar toBucketPath = function toBucketPath(position) {\n  var bucket = position.bucket;\n  var positionInBucket = position.pos;\n  var path = [{\n    bucket: bucket,\n    prefix: toPrefix(positionInBucket)\n  }];\n  bucket = position.bucket._parent;\n  positionInBucket = position.bucket._posAtParent;\n\n  while (bucket) {\n    path.push({\n      bucket: bucket,\n      prefix: toPrefix(positionInBucket)\n    });\n    positionInBucket = bucket._posAtParent;\n    bucket = bucket._parent;\n  }\n\n  path.reverse();\n  return path;\n};\n\nmodule.exports = addLink;","map":{"version":3,"sources":["/Users/yenerkaraca/Documents/GitHub/eth-app/node_modules/ipfs/src/core/components/files/utils/add-link.js"],"names":["require","DAGLink","DAGNode","CID","log","UnixFS","DirSharded","updateHamtDirectory","recreateHamtLevel","createShard","toPrefix","addLinksToHamtBucket","errCode","mc","mh","multihash","last","addLink","context","options","parentCid","parent","Error","isCID","ipld","get","cid","name","size","meta","unmarshal","Data","type","addToShardedDirectory","Links","length","shardSplitThreshold","convertToShardedDirectory","mtime","mode","addToDirectory","map","link","Name","Tsize","Hash","concat","result","rmLink","node","Date","marshal","hashAlg","names","put","DAG_PB","cidVersion","onlyHash","flush","addFileToShardedDirectory","shard","path","block","oldLink","find","substring","prefix","newLink","bucket","file","rootBucket","root","dir","parentKey","dirty","flat","_bucket","_findNewBucketAndPos","position","toBucketPath","index","segment","subShard","parseInt","push","pos","nextSegment","positionInBucket","_parent","_posAtParent","reverse","module","exports"],"mappings":"AAAA;;;;;;;;eAKIA,OAAO,CAAC,aAAD,C;IAFTC,O,YAAAA,O;IACAC,O,YAAAA,O;;AAEF,IAAMC,GAAG,GAAGH,OAAO,CAAC,MAAD,CAAnB;;AACA,IAAMI,GAAG,GAAGJ,OAAO,CAAC,OAAD,CAAP,CAAiB,8BAAjB,CAAZ;;AACA,IAAMK,MAAM,GAAGL,OAAO,CAAC,aAAD,CAAtB;;AACA,IAAMM,UAAU,GAAGN,OAAO,CAAC,sCAAD,CAA1B;;gBAOIA,OAAO,CAAC,cAAD,C;IALTO,mB,aAAAA,mB;IACAC,iB,aAAAA,iB;IACAC,W,aAAAA,W;IACAC,Q,aAAAA,Q;IACAC,oB,aAAAA,oB;;AAEF,IAAMC,OAAO,GAAGZ,OAAO,CAAC,UAAD,CAAvB;;AACA,IAAMa,EAAE,GAAGb,OAAO,CAAC,YAAD,CAAlB;;AACA,IAAMc,EAAE,GAAGd,OAAO,CAAC,oBAAD,CAAP,CAA8Be,SAAzC;;AACA,IAAMC,IAAI,GAAGhB,OAAO,CAAC,SAAD,CAApB;;AAEA,IAAMiB,OAAO;AAAA,sEAAG,iBAAOC,OAAP,EAAgBC,OAAhB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACV,CAACA,OAAO,CAACC,SAAT,IAAsB,CAACD,OAAO,CAACE,MADrB;AAAA;AAAA;AAAA;;AAAA,kBAENT,OAAO,CAAC,IAAIU,KAAJ,CAAU,yCAAV,CAAD,EAAuD,gBAAvD,CAFD;;AAAA;AAAA,kBAKVH,OAAO,CAACC,SAAR,IAAqB,CAACjB,GAAG,CAACoB,KAAJ,CAAUJ,OAAO,CAACC,SAAlB,CALZ;AAAA;AAAA;AAAA;;AAAA,kBAMNR,OAAO,CAAC,IAAIU,KAAJ,CAAU,+BAAV,CAAD,EAA6C,mBAA7C,CAND;;AAAA;AAAA,gBASTH,OAAO,CAACE,MATC;AAAA;AAAA;AAAA;;AAUZjB,YAAAA,GAAG,+BAAwBe,OAAO,CAACC,SAAhC,EAAH;AAVY;AAAA,mBAYWF,OAAO,CAACM,IAAR,CAAaC,GAAb,CAAiBN,OAAO,CAACC,SAAzB,CAZX;;AAAA;AAYZD,YAAAA,OAAO,CAACE,MAZI;;AAAA;AAAA,gBAeTF,OAAO,CAACO,GAfC;AAAA;AAAA;AAAA;;AAAA,kBAgBNd,OAAO,CAAC,IAAIU,KAAJ,CAAU,gCAAV,CAAD,EAA8C,kBAA9C,CAhBD;;AAAA;AAAA,gBAmBTH,OAAO,CAACQ,IAnBC;AAAA;AAAA;AAAA;;AAAA,kBAoBNf,OAAO,CAAC,IAAIU,KAAJ,CAAU,iCAAV,CAAD,EAA+C,mBAA/C,CApBD;;AAAA;AAuBd,gBAAI,CAACnB,GAAG,CAACoB,KAAJ,CAAUJ,OAAO,CAACO,GAAlB,CAAL,EAA6B;AAC3BP,cAAAA,OAAO,CAACO,GAAR,GAAc,IAAIvB,GAAJ,CAAQgB,OAAO,CAACO,GAAhB,CAAd;AACD;;AAzBa,kBA2BV,CAACP,OAAO,CAACS,IAAT,IAAiBT,OAAO,CAACS,IAAR,KAAiB,CA3BxB;AAAA;AAAA;AAAA;;AAAA,kBA4BNhB,OAAO,CAAC,IAAIU,KAAJ,CAAU,iCAAV,CAAD,EAA+C,mBAA/C,CA5BD;;AAAA;AA+BRO,YAAAA,IA/BQ,GA+BDxB,MAAM,CAACyB,SAAP,CAAiBX,OAAO,CAACE,MAAR,CAAeU,IAAhC,CA/BC;;AAAA,kBAiCVF,IAAI,CAACG,IAAL,KAAc,wBAjCJ;AAAA;AAAA;AAAA;;AAkCZ5B,YAAAA,GAAG,CAAC,kCAAD,CAAH;AAlCY,6CAoCL6B,qBAAqB,CAACf,OAAD,EAAUC,OAAV,CApChB;;AAAA;AAAA,kBAuCVA,OAAO,CAACE,MAAR,CAAea,KAAf,CAAqBC,MAArB,IAA+BhB,OAAO,CAACiB,mBAvC7B;AAAA;AAAA;AAAA;;AAwCZhC,YAAAA,GAAG,CAAC,2CAAD,CAAH;AAxCY,6CA0CLiC,yBAAyB,CAACnB,OAAD,kCAC3BC,OAD2B;AAE9BmB,cAAAA,KAAK,EAAET,IAAI,CAACS,KAFkB;AAG9BC,cAAAA,IAAI,EAAEV,IAAI,CAACU;AAHmB,eA1CpB;;AAAA;AAiDdnC,YAAAA,GAAG,kBAAWe,OAAO,CAACQ,IAAnB,eAA4BR,OAAO,CAACO,GAApC,4BAAH;AAjDc,6CAmDPc,cAAc,CAACtB,OAAD,EAAUC,OAAV,CAnDP;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAAH;;AAAA,kBAAPF,OAAO;AAAA;AAAA;AAAA,GAAb;;AAsDA,IAAMoB,yBAAyB;AAAA,uEAAG,kBAAOnB,OAAP,EAAgBC,OAAhB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBACXV,WAAW,CAACS,OAAD,EAAUC,OAAO,CAACE,MAAR,CAAea,KAAf,CAAqBO,GAArB,CAAyB,UAAAC,IAAI;AAAA,qBAAK;AAC1Ef,gBAAAA,IAAI,EAAEe,IAAI,CAACC,IAD+D;AAE1Ef,gBAAAA,IAAI,EAAEc,IAAI,CAACE,KAF+D;AAG1ElB,gBAAAA,GAAG,EAAEgB,IAAI,CAACG;AAHgE,eAAL;AAAA,aAA7B,EAItCC,MAJsC,CAI/B;AACTnB,cAAAA,IAAI,EAAER,OAAO,CAACQ,IADL;AAETC,cAAAA,IAAI,EAAET,OAAO,CAACS,IAFL;AAGTF,cAAAA,GAAG,EAAEP,OAAO,CAACO;AAHJ,aAJ+B,CAAV,EAQ5BP,OAR4B,CADA;;AAAA;AAC1B4B,YAAAA,MAD0B;AAWhC3C,YAAAA,GAAG,oDAA6C2C,MAAM,CAACrB,GAApD,EAAH;AAXgC,8CAazBqB,MAbyB;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAAH;;AAAA,kBAAzBV,yBAAyB;AAAA;AAAA;AAAA,GAA/B;;AAgBA,IAAMG,cAAc;AAAA,uEAAG,kBAAOtB,OAAP,EAAgBC,OAAhB;AAAA;AAAA;AAAA;AAAA;AAAA;AACrBA,YAAAA,OAAO,CAACE,MAAR,CAAe2B,MAAf,CAAsB7B,OAAO,CAACQ,IAA9B;AACAR,YAAAA,OAAO,CAACE,MAAR,CAAeJ,OAAf,CAAuB,IAAIhB,OAAJ,CAAYkB,OAAO,CAACQ,IAApB,EAA0BR,OAAO,CAACS,IAAlC,EAAwCT,OAAO,CAACO,GAAhD,CAAvB;AAEMuB,YAAAA,IAJe,GAIR5C,MAAM,CAACyB,SAAP,CAAiBX,OAAO,CAACE,MAAR,CAAeU,IAAhC,CAJQ;;AAMrB,gBAAIkB,IAAI,CAACX,KAAT,EAAgB;AACd;AACAW,cAAAA,IAAI,CAACX,KAAL,GAAa,IAAIY,IAAJ,EAAb;AAEA/B,cAAAA,OAAO,CAACE,MAAR,GAAiB,IAAInB,OAAJ,CAAY+C,IAAI,CAACE,OAAL,EAAZ,EAA4BhC,OAAO,CAACE,MAAR,CAAea,KAA3C,CAAjB;AACD;;AAEKkB,YAAAA,OAbe,GAaLtC,EAAE,CAACuC,KAAH,CAASlC,OAAO,CAACiC,OAAjB,CAbK,EAerB;;AAfqB;AAAA,mBAgBHlC,OAAO,CAACM,IAAR,CAAa8B,GAAb,CAAiBnC,OAAO,CAACE,MAAzB,EAAiCR,EAAE,CAAC0C,MAApC,EAA4C;AAC5DC,cAAAA,UAAU,EAAErC,OAAO,CAACqC,UADwC;AAE5DJ,cAAAA,OAAO,EAAPA,OAF4D;AAG5DK,cAAAA,QAAQ,EAAE,CAACtC,OAAO,CAACuC;AAHyC,aAA5C,CAhBG;;AAAA;AAgBfhC,YAAAA,GAhBe;AAAA,8CAsBd;AACLuB,cAAAA,IAAI,EAAE9B,OAAO,CAACE,MADT;AAELK,cAAAA,GAAG,EAAHA,GAFK;AAGLE,cAAAA,IAAI,EAAET,OAAO,CAACE,MAAR,CAAeO;AAHhB,aAtBc;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAAH;;AAAA,kBAAdY,cAAc;AAAA;AAAA;AAAA,GAApB;;AA6BA,IAAMP,qBAAqB;AAAA,uEAAG,kBAAOf,OAAP,EAAgBC,OAAhB;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBAGlBwC,yBAAyB,CAACzC,OAAD,EAAUC,OAAV,CAHP;;AAAA;AAAA;AAE1ByC,YAAAA,KAF0B,yBAE1BA,KAF0B;AAEnBC,YAAAA,IAFmB,yBAEnBA,IAFmB;AAAA;AAAA,mBAKP7C,IAAI,CAAC4C,KAAK,CAACF,KAAN,CAAY,EAAZ,EAAgBxC,OAAO,CAAC4C,KAAxB,CAAD,CALG;;AAAA;AAKtBf,YAAAA,MALsB;AAAA;AAAA,mBAMT7B,OAAO,CAACM,IAAR,CAAaC,GAAb,CAAiBsB,MAAM,CAACrB,GAAxB,CANS;;AAAA;AAMtBuB,YAAAA,IANsB;AAQ5B;AACMc,YAAAA,OATsB,GASZ5C,OAAO,CAACE,MAAR,CAAea,KAAf,CACb8B,IADa,CACR,UAAAtB,IAAI;AAAA,qBAAIA,IAAI,CAACC,IAAL,CAAUsB,SAAV,CAAoB,CAApB,EAAuB,CAAvB,MAA8BJ,IAAI,CAAC,CAAD,CAAJ,CAAQK,MAA1C;AAAA,aADI,CATY;AAYtBC,YAAAA,OAZsB,GAYZlB,IAAI,CAACf,KAAL,CACb8B,IADa,CACR,UAAAtB,IAAI;AAAA,qBAAIA,IAAI,CAACC,IAAL,CAAUsB,SAAV,CAAoB,CAApB,EAAuB,CAAvB,MAA8BJ,IAAI,CAAC,CAAD,CAAJ,CAAQK,MAA1C;AAAA,aADI,CAZY;;AAe5B,gBAAIH,OAAJ,EAAa;AACX5C,cAAAA,OAAO,CAACE,MAAR,CAAe2B,MAAf,CAAsBe,OAAO,CAACpB,IAA9B;AACD;;AAEDxB,YAAAA,OAAO,CAACE,MAAR,CAAeJ,OAAf,CAAuBkD,OAAvB;AAnB4B,8CAqBrB5D,mBAAmB,CAACW,OAAD,EAAUC,OAAO,CAACE,MAAR,CAAea,KAAzB,EAAgC2B,IAAI,CAAC,CAAD,CAAJ,CAAQO,MAAxC,EAAgDjD,OAAhD,CArBE;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAAH;;AAAA,kBAArBc,qBAAqB;AAAA;AAAA;AAAA,GAA3B;;AAwBA,IAAM0B,yBAAyB;AAAA,uEAAG,kBAAOzC,OAAP,EAAgBC,OAAhB;AAAA;;AAAA;AAAA;AAAA;AAAA;AAC1BkD,YAAAA,IAD0B,GACnB;AACX1C,cAAAA,IAAI,EAAER,OAAO,CAACQ,IADH;AAEXD,cAAAA,GAAG,EAAEP,OAAO,CAACO,GAFF;AAGXE,cAAAA,IAAI,EAAET,OAAO,CAACS;AAHH,aADmB,EAOhC;;AAPgC;AAAA,mBAQPpB,iBAAiB,CAACW,OAAO,CAACE,MAAR,CAAea,KAAhB,CARV;;AAAA;AAQ1BoC,YAAAA,UAR0B;AAS1BrB,YAAAA,IAT0B,GASnB5C,MAAM,CAACyB,SAAP,CAAiBX,OAAO,CAACE,MAAR,CAAeU,IAAhC,CATmB;AAW1B6B,YAAAA,KAX0B,GAWlB,IAAItD,UAAJ,CAAe;AAC3BiE,cAAAA,IAAI,EAAE,IADqB;AAE3BC,cAAAA,GAAG,EAAE,IAFsB;AAG3BnD,cAAAA,MAAM,EAAE,IAHmB;AAI3BoD,cAAAA,SAAS,EAAE,IAJgB;AAK3BZ,cAAAA,IAAI,EAAE,EALqB;AAM3Ba,cAAAA,KAAK,EAAE,IANoB;AAO3BC,cAAAA,IAAI,EAAE,KAPqB;AAQ3BpC,cAAAA,IAAI,EAAEU,IAAI,CAACV;AARgB,aAAf,EASXpB,OATW,CAXkB;AAqBhCyC,YAAAA,KAAK,CAACgB,OAAN,GAAgBN,UAAhB;;AAEA,gBAAIrB,IAAI,CAACX,KAAT,EAAgB;AACd;AACAsB,cAAAA,KAAK,CAACtB,KAAN,GAAc,IAAIY,IAAJ,EAAd;AACD,aA1B+B,CA4BhC;;;AA5BgC;AAAA,mBA6BToB,UAAU,CAACO,oBAAX,CAAgCR,IAAI,CAAC1C,IAArC,CA7BS;;AAAA;AA6B1BmD,YAAAA,QA7B0B;AA8B1BjB,YAAAA,IA9B0B,GA8BnBkB,YAAY,CAACD,QAAD,CA9BO;AA+BhCjB,YAAAA,IAAI,CAAC,CAAD,CAAJ,CAAQZ,IAAR,GAAe9B,OAAO,CAACE,MAAvB;AACI2D,YAAAA,KAhC4B,GAgCpB,CAhCoB;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAmCxBC,sBAAAA,OAnCwB,GAmCdpB,IAAI,CAACmB,KAAD,CAnCU;AAoC9BA,sBAAAA,KAAK;AACC/B,sBAAAA,IArCwB,GAqCjBgC,OAAO,CAAChC,IArCS;AAuCxBP,sBAAAA,IAvCwB,GAuCjBO,IAAI,CAACf,KAAL,CACV8B,IADU,CACL,UAAAtB,IAAI;AAAA,+BAAIA,IAAI,CAACC,IAAL,CAAUsB,SAAV,CAAoB,CAApB,EAAuB,CAAvB,MAA8BgB,OAAO,CAACf,MAA1C;AAAA,uBADC,CAvCiB;;AAAA,0BA0CzBxB,IA1CyB;AAAA;AAAA;AAAA;;AA2C5B;AACAtC,sBAAAA,GAAG,gBAAS6E,OAAO,CAACf,MAAjB,SAA0BG,IAAI,CAAC1C,IAA/B,oBAAH;AACAqD,sBAAAA,KAAK,GAAGnB,IAAI,CAAC1B,MAAb;AA7C4B;;AAAA;AAAA,4BAkD1BO,IAAI,CAACC,IAAL,eAAiBsC,OAAO,CAACf,MAAzB,SAAkCG,IAAI,CAAC1C,IAAvC,CAlD0B;AAAA;AAAA;AAAA;;AAmD5B;AACAvB,sBAAAA,GAAG,gBAAS6E,OAAO,CAACf,MAAjB,SAA0BG,IAAI,CAAC1C,IAA/B,uBAAH;AACAqD,sBAAAA,KAAK,GAAGnB,IAAI,CAAC1B,MAAb;AArD4B;;AAAA;AAAA,4BA0D1BO,IAAI,CAACC,IAAL,CAAUR,MAAV,GAAmB,CA1DO;AAAA;AAAA;AAAA;;AA2D5B;AACA/B,sBAAAA,GAAG,gBAASsC,IAAI,CAACC,IAAd,cAAsBD,IAAI,CAACG,IAA3B,uCAAH;AACAmC,sBAAAA,KAAK,GAAGnB,IAAI,CAAC1B,MAAb;AA7D4B;;AAAA;AAkE9B;AACA/B,sBAAAA,GAAG,0BAAmB6E,OAAO,CAACf,MAA3B,EAAH;AAnE8B;AAAA,6BAoEPhD,OAAO,CAACM,IAAR,CAAaC,GAAb,CAAiBiB,IAAI,CAACG,IAAtB,CApEO;;AAAA;AAoExBqC,sBAAAA,QApEwB;;AAAA,0BAuEzBrB,IAAI,CAACmB,KAAD,CAvEqB;AAAA;AAAA;AAAA;;AAwE5B5E,sBAAAA,GAAG,+BAAwB6E,OAAO,CAACf,MAAhC,EAAH;AAxE4B;AAAA,6BAyEtB1D,iBAAiB,CAAC0E,QAAQ,CAAChD,KAAV,EAAiBoC,UAAjB,EAA6BW,OAAO,CAACb,MAArC,EAA6Ce,QAAQ,CAACF,OAAO,CAACf,MAAT,EAAiB,EAAjB,CAArD,CAzEK;;AAAA;AAAA;AAAA,6BA2ELI,UAAU,CAACO,oBAAX,CAAgCR,IAAI,CAAC1C,IAArC,CA3EK;;AAAA;AA2EtBmD,sBAAAA,SA3EsB;AA6E5BjB,sBAAAA,IAAI,CAACuB,IAAL,CAAU;AACRhB,wBAAAA,MAAM,EAAEU,SAAQ,CAACV,MADT;AAERF,wBAAAA,MAAM,EAAExD,QAAQ,CAACoE,SAAQ,CAACO,GAAV,CAFR;AAGRpC,wBAAAA,IAAI,EAAEiC;AAHE,uBAAV;AA7E4B;;AAAA;AAsFxBI,sBAAAA,WAtFwB,GAsFVzB,IAAI,CAACmB,KAAD,CAtFM,EAwF9B;;AAxF8B;AAAA,6BAyFxBrE,oBAAoB,CAACuE,QAAQ,CAAChD,KAAV,EAAiBoD,WAAW,CAAClB,MAA7B,EAAqCE,UAArC,CAzFI;;AAAA;AA2F9BgB,sBAAAA,WAAW,CAACrC,IAAZ,GAAmBiC,QAAnB;;AA3F8B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA,kBAkCzBF,KAAK,GAAGnB,IAAI,CAAC1B,MAlCY;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA,mBA+F1ByB,KAAK,CAACgB,OAAN,CAActB,GAAd,CAAkBe,IAAI,CAAC1C,IAAvB,EAA6B;AACjCC,cAAAA,IAAI,EAAEyC,IAAI,CAACzC,IADsB;AAEjCF,cAAAA,GAAG,EAAE2C,IAAI,CAAC3C;AAFuB,aAA7B,CA/F0B;;AAAA;AAAA,8CAoGzB;AACLkC,cAAAA,KAAK,EAALA,KADK;AACEC,cAAAA,IAAI,EAAJA;AADF,aApGyB;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAAH;;AAAA,kBAAzBF,yBAAyB;AAAA;AAAA;AAAA,GAA/B;;AAyGA,IAAMoB,YAAY,GAAG,SAAfA,YAAe,CAACD,QAAD,EAAc;AACjC,MAAIV,MAAM,GAAGU,QAAQ,CAACV,MAAtB;AACA,MAAImB,gBAAgB,GAAGT,QAAQ,CAACO,GAAhC;AACA,MAAMxB,IAAI,GAAG,CAAC;AACZO,IAAAA,MAAM,EAANA,MADY;AAEZF,IAAAA,MAAM,EAAExD,QAAQ,CAAC6E,gBAAD;AAFJ,GAAD,CAAb;AAKAnB,EAAAA,MAAM,GAAGU,QAAQ,CAACV,MAAT,CAAgBoB,OAAzB;AACAD,EAAAA,gBAAgB,GAAGT,QAAQ,CAACV,MAAT,CAAgBqB,YAAnC;;AAEA,SAAOrB,MAAP,EAAe;AACbP,IAAAA,IAAI,CAACuB,IAAL,CAAU;AACRhB,MAAAA,MAAM,EAANA,MADQ;AAERF,MAAAA,MAAM,EAAExD,QAAQ,CAAC6E,gBAAD;AAFR,KAAV;AAKAA,IAAAA,gBAAgB,GAAGnB,MAAM,CAACqB,YAA1B;AACArB,IAAAA,MAAM,GAAGA,MAAM,CAACoB,OAAhB;AACD;;AAED3B,EAAAA,IAAI,CAAC6B,OAAL;AAEA,SAAO7B,IAAP;AACD,CAxBD;;AA0BA8B,MAAM,CAACC,OAAP,GAAiB3E,OAAjB","sourcesContent":["'use strict'\n\nconst {\n  DAGLink,\n  DAGNode\n} = require('ipld-dag-pb')\nconst CID = require('cids')\nconst log = require('debug')('ipfs:mfs:core:utils:add-link')\nconst UnixFS = require('ipfs-unixfs')\nconst DirSharded = require('ipfs-unixfs-importer/src/dir-sharded')\nconst {\n  updateHamtDirectory,\n  recreateHamtLevel,\n  createShard,\n  toPrefix,\n  addLinksToHamtBucket\n} = require('./hamt-utils')\nconst errCode = require('err-code')\nconst mc = require('multicodec')\nconst mh = require('multihashing-async').multihash\nconst last = require('it-last')\n\nconst addLink = async (context, options) => {\n  if (!options.parentCid && !options.parent) {\n    throw errCode(new Error('No parent node or CID passed to addLink'), 'EINVALIDPARENT')\n  }\n\n  if (options.parentCid && !CID.isCID(options.parentCid)) {\n    throw errCode(new Error('Invalid CID passed to addLink'), 'EINVALIDPARENTCID')\n  }\n\n  if (!options.parent) {\n    log(`Loading parent node ${options.parentCid}`)\n\n    options.parent = await context.ipld.get(options.parentCid)\n  }\n\n  if (!options.cid) {\n    throw errCode(new Error('No child cid passed to addLink'), 'EINVALIDCHILDCID')\n  }\n\n  if (!options.name) {\n    throw errCode(new Error('No child name passed to addLink'), 'EINVALIDCHILDNAME')\n  }\n\n  if (!CID.isCID(options.cid)) {\n    options.cid = new CID(options.cid)\n  }\n\n  if (!options.size && options.size !== 0) {\n    throw errCode(new Error('No child size passed to addLink'), 'EINVALIDCHILDSIZE')\n  }\n\n  const meta = UnixFS.unmarshal(options.parent.Data)\n\n  if (meta.type === 'hamt-sharded-directory') {\n    log('Adding link to sharded directory')\n\n    return addToShardedDirectory(context, options)\n  }\n\n  if (options.parent.Links.length >= options.shardSplitThreshold) {\n    log('Converting directory to sharded directory')\n\n    return convertToShardedDirectory(context, {\n      ...options,\n      mtime: meta.mtime,\n      mode: meta.mode\n    })\n  }\n\n  log(`Adding ${options.name} (${options.cid}) to regular directory`)\n\n  return addToDirectory(context, options)\n}\n\nconst convertToShardedDirectory = async (context, options) => {\n  const result = await createShard(context, options.parent.Links.map(link => ({\n    name: link.Name,\n    size: link.Tsize,\n    cid: link.Hash\n  })).concat({\n    name: options.name,\n    size: options.size,\n    cid: options.cid\n  }), options)\n\n  log(`Converted directory to sharded directory ${result.cid}`)\n\n  return result\n}\n\nconst addToDirectory = async (context, options) => {\n  options.parent.rmLink(options.name)\n  options.parent.addLink(new DAGLink(options.name, options.size, options.cid))\n\n  const node = UnixFS.unmarshal(options.parent.Data)\n\n  if (node.mtime) {\n    // Update mtime if previously set\n    node.mtime = new Date()\n\n    options.parent = new DAGNode(node.marshal(), options.parent.Links)\n  }\n\n  const hashAlg = mh.names[options.hashAlg]\n\n  // Persist the new parent DAGNode\n  const cid = await context.ipld.put(options.parent, mc.DAG_PB, {\n    cidVersion: options.cidVersion,\n    hashAlg,\n    onlyHash: !options.flush\n  })\n\n  return {\n    node: options.parent,\n    cid,\n    size: options.parent.size\n  }\n}\n\nconst addToShardedDirectory = async (context, options) => {\n  const {\n    shard, path\n  } = await addFileToShardedDirectory(context, options)\n\n  const result = await last(shard.flush('', context.block))\n  const node = await context.ipld.get(result.cid)\n\n  // we have written out the shard, but only one sub-shard will have been written so replace it in the original shard\n  const oldLink = options.parent.Links\n    .find(link => link.Name.substring(0, 2) === path[0].prefix)\n\n  const newLink = node.Links\n    .find(link => link.Name.substring(0, 2) === path[0].prefix)\n\n  if (oldLink) {\n    options.parent.rmLink(oldLink.Name)\n  }\n\n  options.parent.addLink(newLink)\n\n  return updateHamtDirectory(context, options.parent.Links, path[0].bucket, options)\n}\n\nconst addFileToShardedDirectory = async (context, options) => {\n  const file = {\n    name: options.name,\n    cid: options.cid,\n    size: options.size\n  }\n\n  // start at the root bucket and descend, loading nodes as we go\n  const rootBucket = await recreateHamtLevel(options.parent.Links)\n  const node = UnixFS.unmarshal(options.parent.Data)\n\n  const shard = new DirSharded({\n    root: true,\n    dir: true,\n    parent: null,\n    parentKey: null,\n    path: '',\n    dirty: true,\n    flat: false,\n    mode: node.mode\n  }, options)\n  shard._bucket = rootBucket\n\n  if (node.mtime) {\n    // update mtime if previously set\n    shard.mtime = new Date()\n  }\n\n  // load subshards until the bucket & position no longer changes\n  const position = await rootBucket._findNewBucketAndPos(file.name)\n  const path = toBucketPath(position)\n  path[0].node = options.parent\n  let index = 0\n\n  while (index < path.length) {\n    const segment = path[index]\n    index++\n    const node = segment.node\n\n    const link = node.Links\n      .find(link => link.Name.substring(0, 2) === segment.prefix)\n\n    if (!link) {\n      // prefix is new, file will be added to the current bucket\n      log(`Link ${segment.prefix}${file.name} will be added`)\n      index = path.length\n\n      break\n    }\n\n    if (link.Name === `${segment.prefix}${file.name}`) {\n      // file already existed, file will be added to the current bucket\n      log(`Link ${segment.prefix}${file.name} will be replaced`)\n      index = path.length\n\n      break\n    }\n\n    if (link.Name.length > 2) {\n      // another file had the same prefix, will be replaced with a subshard\n      log(`Link ${link.Name} ${link.Hash} will be replaced with a subshard`)\n      index = path.length\n\n      break\n    }\n\n    // load sub-shard\n    log(`Found subshard ${segment.prefix}`)\n    const subShard = await context.ipld.get(link.Hash)\n\n    // subshard hasn't been loaded, descend to the next level of the HAMT\n    if (!path[index]) {\n      log(`Loaded new subshard ${segment.prefix}`)\n      await recreateHamtLevel(subShard.Links, rootBucket, segment.bucket, parseInt(segment.prefix, 16))\n\n      const position = await rootBucket._findNewBucketAndPos(file.name)\n\n      path.push({\n        bucket: position.bucket,\n        prefix: toPrefix(position.pos),\n        node: subShard\n      })\n\n      break\n    }\n\n    const nextSegment = path[index]\n\n    // add next levels worth of links to bucket\n    await addLinksToHamtBucket(subShard.Links, nextSegment.bucket, rootBucket)\n\n    nextSegment.node = subShard\n  }\n\n  // finally add the new file into the shard\n  await shard._bucket.put(file.name, {\n    size: file.size,\n    cid: file.cid\n  })\n\n  return {\n    shard, path\n  }\n}\n\nconst toBucketPath = (position) => {\n  let bucket = position.bucket\n  let positionInBucket = position.pos\n  const path = [{\n    bucket,\n    prefix: toPrefix(positionInBucket)\n  }]\n\n  bucket = position.bucket._parent\n  positionInBucket = position.bucket._posAtParent\n\n  while (bucket) {\n    path.push({\n      bucket,\n      prefix: toPrefix(positionInBucket)\n    })\n\n    positionInBucket = bucket._posAtParent\n    bucket = bucket._parent\n  }\n\n  path.reverse()\n\n  return path\n}\n\nmodule.exports = addLink\n"]},"metadata":{},"sourceType":"script"}