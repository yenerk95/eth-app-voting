{"ast":null,"code":"'use strict';\n\nconst errCode = require('err-code');\n\nconst UnixFS = require('ipfs-unixfs');\n\nconst persist = require('../../utils/persist');\n\nconst {\n  DAGNode,\n  DAGLink\n} = require('ipld-dag-pb');\n\nconst all = require('it-all');\n\nconst parallelBatch = require('it-parallel-batch');\n\nconst mh = require('multihashing-async').multihash;\n\nconst dagBuilders = {\n  flat: require('./flat'),\n  balanced: require('./balanced'),\n  trickle: require('./trickle')\n};\n\nasync function* buildFileBatch(file, source, block, options) {\n  let count = -1;\n  let previous;\n  let bufferImporter;\n\n  if (typeof options.bufferImporter === 'function') {\n    bufferImporter = options.bufferImporter;\n  } else {\n    bufferImporter = require('./buffer-importer');\n  }\n\n  for await (const entry of parallelBatch(bufferImporter(file, source, block, options), options.blockWriteConcurrency)) {\n    count++;\n\n    if (count === 0) {\n      previous = entry;\n      continue;\n    } else if (count === 1) {\n      yield previous;\n      previous = null;\n    }\n\n    yield entry;\n  }\n\n  if (previous) {\n    previous.single = true;\n    yield previous;\n  }\n}\n\nconst reduce = (file, block, options) => {\n  return async function (leaves) {\n    if (leaves.length === 1 && leaves[0].single && options.reduceSingleLeafToSelf) {\n      const leaf = leaves[0];\n\n      if (leaf.cid.codec === 'raw' && (file.mtime !== undefined || file.mode !== undefined)) {\n        // only one leaf node which is a buffer - we have metadata so convert it into a\n        // UnixFS entry otherwise we'll have nowhere to store the metadata\n        let {\n          data: buffer\n        } = await block.get(leaf.cid, options);\n        leaf.unixfs = new UnixFS({\n          type: 'file',\n          mtime: file.mtime,\n          mode: file.mode,\n          data: buffer\n        });\n        const multihash = mh.decode(leaf.cid.multihash);\n        buffer = new DAGNode(leaf.unixfs.marshal()).serialize();\n        leaf.cid = await persist(buffer, block, { ...options,\n          codec: 'dag-pb',\n          hashAlg: multihash.name,\n          cidVersion: options.cidVersion\n        });\n        leaf.size = buffer.length;\n      }\n\n      return {\n        cid: leaf.cid,\n        path: file.path,\n        unixfs: leaf.unixfs,\n        size: leaf.size\n      };\n    } // create a parent node and add all the leaves\n\n\n    const f = new UnixFS({\n      type: 'file',\n      mtime: file.mtime,\n      mode: file.mode\n    });\n    const links = leaves.filter(leaf => {\n      if (leaf.cid.codec === 'raw' && leaf.size) {\n        return true;\n      }\n\n      if (!leaf.unixfs.data && leaf.unixfs.fileSize()) {\n        return true;\n      }\n\n      return Boolean(leaf.unixfs.data.length);\n    }).map(leaf => {\n      if (leaf.cid.codec === 'raw') {\n        // node is a leaf buffer\n        f.addBlockSize(leaf.size);\n        return new DAGLink(leaf.name, leaf.size, leaf.cid);\n      }\n\n      if (!leaf.unixfs.data) {\n        // node is an intermediate node\n        f.addBlockSize(leaf.unixfs.fileSize());\n      } else {\n        // node is a unixfs 'file' leaf node\n        f.addBlockSize(leaf.unixfs.data.length);\n      }\n\n      return new DAGLink(leaf.name, leaf.size, leaf.cid);\n    });\n    const node = new DAGNode(f.marshal(), links);\n    const buffer = node.serialize();\n    const cid = await persist(buffer, block, options);\n    return {\n      cid,\n      path: file.path,\n      unixfs: f,\n      size: buffer.length + node.Links.reduce((acc, curr) => acc + curr.Tsize, 0)\n    };\n  };\n};\n\nconst fileBuilder = async (file, source, block, options) => {\n  const dagBuilder = dagBuilders[options.strategy];\n\n  if (!dagBuilder) {\n    throw errCode(new Error(`Unknown importer build strategy name: ${options.strategy}`), 'ERR_BAD_STRATEGY');\n  }\n\n  const roots = await all(dagBuilder(buildFileBatch(file, source, block, options), reduce(file, block, options), options));\n\n  if (roots.length > 1) {\n    throw errCode(new Error('expected a maximum of 1 roots and got ' + roots.length), 'ETOOMANYROOTS');\n  }\n\n  return roots[0];\n};\n\nmodule.exports = fileBuilder;","map":{"version":3,"sources":["/Users/yenerkaraca/Documents/GitHub/eth-app/node_modules/ipfs-unixfs-importer/src/dag-builder/file/index.js"],"names":["errCode","require","UnixFS","persist","DAGNode","DAGLink","all","parallelBatch","mh","multihash","dagBuilders","flat","balanced","trickle","buildFileBatch","file","source","block","options","count","previous","bufferImporter","entry","blockWriteConcurrency","single","reduce","leaves","length","reduceSingleLeafToSelf","leaf","cid","codec","mtime","undefined","mode","data","buffer","get","unixfs","type","decode","marshal","serialize","hashAlg","name","cidVersion","size","path","f","links","filter","fileSize","Boolean","map","addBlockSize","node","Links","acc","curr","Tsize","fileBuilder","dagBuilder","strategy","Error","roots","module","exports"],"mappings":"AAAA;;AAEA,MAAMA,OAAO,GAAGC,OAAO,CAAC,UAAD,CAAvB;;AACA,MAAMC,MAAM,GAAGD,OAAO,CAAC,aAAD,CAAtB;;AACA,MAAME,OAAO,GAAGF,OAAO,CAAC,qBAAD,CAAvB;;AACA,MAAM;AACJG,EAAAA,OADI;AAEJC,EAAAA;AAFI,IAGFJ,OAAO,CAAC,aAAD,CAHX;;AAIA,MAAMK,GAAG,GAAGL,OAAO,CAAC,QAAD,CAAnB;;AACA,MAAMM,aAAa,GAAGN,OAAO,CAAC,mBAAD,CAA7B;;AACA,MAAMO,EAAE,GAAGP,OAAO,CAAC,oBAAD,CAAP,CAA8BQ,SAAzC;;AAEA,MAAMC,WAAW,GAAG;AAClBC,EAAAA,IAAI,EAAEV,OAAO,CAAC,QAAD,CADK;AAElBW,EAAAA,QAAQ,EAAEX,OAAO,CAAC,YAAD,CAFC;AAGlBY,EAAAA,OAAO,EAAEZ,OAAO,CAAC,WAAD;AAHE,CAApB;;AAMA,gBAAiBa,cAAjB,CAAiCC,IAAjC,EAAuCC,MAAvC,EAA+CC,KAA/C,EAAsDC,OAAtD,EAA+D;AAC7D,MAAIC,KAAK,GAAG,CAAC,CAAb;AACA,MAAIC,QAAJ;AACA,MAAIC,cAAJ;;AAEA,MAAI,OAAOH,OAAO,CAACG,cAAf,KAAkC,UAAtC,EAAkD;AAChDA,IAAAA,cAAc,GAAGH,OAAO,CAACG,cAAzB;AACD,GAFD,MAEO;AACLA,IAAAA,cAAc,GAAGpB,OAAO,CAAC,mBAAD,CAAxB;AACD;;AAED,aAAW,MAAMqB,KAAjB,IAA0Bf,aAAa,CAACc,cAAc,CAACN,IAAD,EAAOC,MAAP,EAAeC,KAAf,EAAsBC,OAAtB,CAAf,EAA+CA,OAAO,CAACK,qBAAvD,CAAvC,EAAsH;AACpHJ,IAAAA,KAAK;;AAEL,QAAIA,KAAK,KAAK,CAAd,EAAiB;AACfC,MAAAA,QAAQ,GAAGE,KAAX;AACA;AACD,KAHD,MAGO,IAAIH,KAAK,KAAK,CAAd,EAAiB;AACtB,YAAMC,QAAN;AACAA,MAAAA,QAAQ,GAAG,IAAX;AACD;;AAED,UAAME,KAAN;AACD;;AAED,MAAIF,QAAJ,EAAc;AACZA,IAAAA,QAAQ,CAACI,MAAT,GAAkB,IAAlB;AACA,UAAMJ,QAAN;AACD;AACF;;AAED,MAAMK,MAAM,GAAG,CAACV,IAAD,EAAOE,KAAP,EAAcC,OAAd,KAA0B;AACvC,SAAO,gBAAgBQ,MAAhB,EAAwB;AAC7B,QAAIA,MAAM,CAACC,MAAP,KAAkB,CAAlB,IAAuBD,MAAM,CAAC,CAAD,CAAN,CAAUF,MAAjC,IAA2CN,OAAO,CAACU,sBAAvD,EAA+E;AAC7E,YAAMC,IAAI,GAAGH,MAAM,CAAC,CAAD,CAAnB;;AAEA,UAAIG,IAAI,CAACC,GAAL,CAASC,KAAT,KAAmB,KAAnB,KAA6BhB,IAAI,CAACiB,KAAL,KAAeC,SAAf,IAA4BlB,IAAI,CAACmB,IAAL,KAAcD,SAAvE,CAAJ,EAAuF;AACrF;AACA;AACA,YAAI;AAAEE,UAAAA,IAAI,EAAEC;AAAR,YAAmB,MAAMnB,KAAK,CAACoB,GAAN,CAAUR,IAAI,CAACC,GAAf,EAAoBZ,OAApB,CAA7B;AAEAW,QAAAA,IAAI,CAACS,MAAL,GAAc,IAAIpC,MAAJ,CAAW;AACvBqC,UAAAA,IAAI,EAAE,MADiB;AAEvBP,UAAAA,KAAK,EAAEjB,IAAI,CAACiB,KAFW;AAGvBE,UAAAA,IAAI,EAAEnB,IAAI,CAACmB,IAHY;AAIvBC,UAAAA,IAAI,EAAEC;AAJiB,SAAX,CAAd;AAOA,cAAM3B,SAAS,GAAGD,EAAE,CAACgC,MAAH,CAAUX,IAAI,CAACC,GAAL,CAASrB,SAAnB,CAAlB;AACA2B,QAAAA,MAAM,GAAG,IAAIhC,OAAJ,CAAYyB,IAAI,CAACS,MAAL,CAAYG,OAAZ,EAAZ,EAAmCC,SAAnC,EAAT;AAEAb,QAAAA,IAAI,CAACC,GAAL,GAAW,MAAM3B,OAAO,CAACiC,MAAD,EAASnB,KAAT,EAAgB,EACtC,GAAGC,OADmC;AAEtCa,UAAAA,KAAK,EAAE,QAF+B;AAGtCY,UAAAA,OAAO,EAAElC,SAAS,CAACmC,IAHmB;AAItCC,UAAAA,UAAU,EAAE3B,OAAO,CAAC2B;AAJkB,SAAhB,CAAxB;AAMAhB,QAAAA,IAAI,CAACiB,IAAL,GAAYV,MAAM,CAACT,MAAnB;AACD;;AAED,aAAO;AACLG,QAAAA,GAAG,EAAED,IAAI,CAACC,GADL;AAELiB,QAAAA,IAAI,EAAEhC,IAAI,CAACgC,IAFN;AAGLT,QAAAA,MAAM,EAAET,IAAI,CAACS,MAHR;AAILQ,QAAAA,IAAI,EAAEjB,IAAI,CAACiB;AAJN,OAAP;AAMD,KAlC4B,CAoC7B;;;AACA,UAAME,CAAC,GAAG,IAAI9C,MAAJ,CAAW;AACnBqC,MAAAA,IAAI,EAAE,MADa;AAEnBP,MAAAA,KAAK,EAAEjB,IAAI,CAACiB,KAFO;AAGnBE,MAAAA,IAAI,EAAEnB,IAAI,CAACmB;AAHQ,KAAX,CAAV;AAMA,UAAMe,KAAK,GAAGvB,MAAM,CACjBwB,MADW,CACJrB,IAAI,IAAI;AACd,UAAIA,IAAI,CAACC,GAAL,CAASC,KAAT,KAAmB,KAAnB,IAA4BF,IAAI,CAACiB,IAArC,EAA2C;AACzC,eAAO,IAAP;AACD;;AAED,UAAI,CAACjB,IAAI,CAACS,MAAL,CAAYH,IAAb,IAAqBN,IAAI,CAACS,MAAL,CAAYa,QAAZ,EAAzB,EAAiD;AAC/C,eAAO,IAAP;AACD;;AAED,aAAOC,OAAO,CAACvB,IAAI,CAACS,MAAL,CAAYH,IAAZ,CAAiBR,MAAlB,CAAd;AACD,KAXW,EAYX0B,GAZW,CAYNxB,IAAD,IAAU;AACb,UAAIA,IAAI,CAACC,GAAL,CAASC,KAAT,KAAmB,KAAvB,EAA8B;AAC5B;AACAiB,QAAAA,CAAC,CAACM,YAAF,CAAezB,IAAI,CAACiB,IAApB;AAEA,eAAO,IAAIzC,OAAJ,CAAYwB,IAAI,CAACe,IAAjB,EAAuBf,IAAI,CAACiB,IAA5B,EAAkCjB,IAAI,CAACC,GAAvC,CAAP;AACD;;AAED,UAAI,CAACD,IAAI,CAACS,MAAL,CAAYH,IAAjB,EAAuB;AACrB;AACAa,QAAAA,CAAC,CAACM,YAAF,CAAezB,IAAI,CAACS,MAAL,CAAYa,QAAZ,EAAf;AACD,OAHD,MAGO;AACL;AACAH,QAAAA,CAAC,CAACM,YAAF,CAAezB,IAAI,CAACS,MAAL,CAAYH,IAAZ,CAAiBR,MAAhC;AACD;;AAED,aAAO,IAAItB,OAAJ,CAAYwB,IAAI,CAACe,IAAjB,EAAuBf,IAAI,CAACiB,IAA5B,EAAkCjB,IAAI,CAACC,GAAvC,CAAP;AACD,KA7BW,CAAd;AA+BA,UAAMyB,IAAI,GAAG,IAAInD,OAAJ,CAAY4C,CAAC,CAACP,OAAF,EAAZ,EAAyBQ,KAAzB,CAAb;AACA,UAAMb,MAAM,GAAGmB,IAAI,CAACb,SAAL,EAAf;AACA,UAAMZ,GAAG,GAAG,MAAM3B,OAAO,CAACiC,MAAD,EAASnB,KAAT,EAAgBC,OAAhB,CAAzB;AAEA,WAAO;AACLY,MAAAA,GADK;AAELiB,MAAAA,IAAI,EAAEhC,IAAI,CAACgC,IAFN;AAGLT,MAAAA,MAAM,EAAEU,CAHH;AAILF,MAAAA,IAAI,EAAEV,MAAM,CAACT,MAAP,GAAgB4B,IAAI,CAACC,KAAL,CAAW/B,MAAX,CAAkB,CAACgC,GAAD,EAAMC,IAAN,KAAeD,GAAG,GAAGC,IAAI,CAACC,KAA5C,EAAmD,CAAnD;AAJjB,KAAP;AAMD,GApFD;AAqFD,CAtFD;;AAwFA,MAAMC,WAAW,GAAG,OAAO7C,IAAP,EAAaC,MAAb,EAAqBC,KAArB,EAA4BC,OAA5B,KAAwC;AAC1D,QAAM2C,UAAU,GAAGnD,WAAW,CAACQ,OAAO,CAAC4C,QAAT,CAA9B;;AAEA,MAAI,CAACD,UAAL,EAAiB;AACf,UAAM7D,OAAO,CAAC,IAAI+D,KAAJ,CAAW,yCAAwC7C,OAAO,CAAC4C,QAAS,EAApE,CAAD,EAAyE,kBAAzE,CAAb;AACD;;AAED,QAAME,KAAK,GAAG,MAAM1D,GAAG,CAACuD,UAAU,CAAC/C,cAAc,CAACC,IAAD,EAAOC,MAAP,EAAeC,KAAf,EAAsBC,OAAtB,CAAf,EAA+CO,MAAM,CAACV,IAAD,EAAOE,KAAP,EAAcC,OAAd,CAArD,EAA6EA,OAA7E,CAAX,CAAvB;;AAEA,MAAI8C,KAAK,CAACrC,MAAN,GAAe,CAAnB,EAAsB;AACpB,UAAM3B,OAAO,CAAC,IAAI+D,KAAJ,CAAU,2CAA2CC,KAAK,CAACrC,MAA3D,CAAD,EAAqE,eAArE,CAAb;AACD;;AAED,SAAOqC,KAAK,CAAC,CAAD,CAAZ;AACD,CAdD;;AAgBAC,MAAM,CAACC,OAAP,GAAiBN,WAAjB","sourcesContent":["'use strict'\n\nconst errCode = require('err-code')\nconst UnixFS = require('ipfs-unixfs')\nconst persist = require('../../utils/persist')\nconst {\n  DAGNode,\n  DAGLink\n} = require('ipld-dag-pb')\nconst all = require('it-all')\nconst parallelBatch = require('it-parallel-batch')\nconst mh = require('multihashing-async').multihash\n\nconst dagBuilders = {\n  flat: require('./flat'),\n  balanced: require('./balanced'),\n  trickle: require('./trickle')\n}\n\nasync function * buildFileBatch (file, source, block, options) {\n  let count = -1\n  let previous\n  let bufferImporter\n\n  if (typeof options.bufferImporter === 'function') {\n    bufferImporter = options.bufferImporter\n  } else {\n    bufferImporter = require('./buffer-importer')\n  }\n\n  for await (const entry of parallelBatch(bufferImporter(file, source, block, options), options.blockWriteConcurrency)) {\n    count++\n\n    if (count === 0) {\n      previous = entry\n      continue\n    } else if (count === 1) {\n      yield previous\n      previous = null\n    }\n\n    yield entry\n  }\n\n  if (previous) {\n    previous.single = true\n    yield previous\n  }\n}\n\nconst reduce = (file, block, options) => {\n  return async function (leaves) {\n    if (leaves.length === 1 && leaves[0].single && options.reduceSingleLeafToSelf) {\n      const leaf = leaves[0]\n\n      if (leaf.cid.codec === 'raw' && (file.mtime !== undefined || file.mode !== undefined)) {\n        // only one leaf node which is a buffer - we have metadata so convert it into a\n        // UnixFS entry otherwise we'll have nowhere to store the metadata\n        let { data: buffer } = await block.get(leaf.cid, options)\n\n        leaf.unixfs = new UnixFS({\n          type: 'file',\n          mtime: file.mtime,\n          mode: file.mode,\n          data: buffer\n        })\n\n        const multihash = mh.decode(leaf.cid.multihash)\n        buffer = new DAGNode(leaf.unixfs.marshal()).serialize()\n\n        leaf.cid = await persist(buffer, block, {\n          ...options,\n          codec: 'dag-pb',\n          hashAlg: multihash.name,\n          cidVersion: options.cidVersion\n        })\n        leaf.size = buffer.length\n      }\n\n      return {\n        cid: leaf.cid,\n        path: file.path,\n        unixfs: leaf.unixfs,\n        size: leaf.size\n      }\n    }\n\n    // create a parent node and add all the leaves\n    const f = new UnixFS({\n      type: 'file',\n      mtime: file.mtime,\n      mode: file.mode\n    })\n\n    const links = leaves\n      .filter(leaf => {\n        if (leaf.cid.codec === 'raw' && leaf.size) {\n          return true\n        }\n\n        if (!leaf.unixfs.data && leaf.unixfs.fileSize()) {\n          return true\n        }\n\n        return Boolean(leaf.unixfs.data.length)\n      })\n      .map((leaf) => {\n        if (leaf.cid.codec === 'raw') {\n          // node is a leaf buffer\n          f.addBlockSize(leaf.size)\n\n          return new DAGLink(leaf.name, leaf.size, leaf.cid)\n        }\n\n        if (!leaf.unixfs.data) {\n          // node is an intermediate node\n          f.addBlockSize(leaf.unixfs.fileSize())\n        } else {\n          // node is a unixfs 'file' leaf node\n          f.addBlockSize(leaf.unixfs.data.length)\n        }\n\n        return new DAGLink(leaf.name, leaf.size, leaf.cid)\n      })\n\n    const node = new DAGNode(f.marshal(), links)\n    const buffer = node.serialize()\n    const cid = await persist(buffer, block, options)\n\n    return {\n      cid,\n      path: file.path,\n      unixfs: f,\n      size: buffer.length + node.Links.reduce((acc, curr) => acc + curr.Tsize, 0)\n    }\n  }\n}\n\nconst fileBuilder = async (file, source, block, options) => {\n  const dagBuilder = dagBuilders[options.strategy]\n\n  if (!dagBuilder) {\n    throw errCode(new Error(`Unknown importer build strategy name: ${options.strategy}`), 'ERR_BAD_STRATEGY')\n  }\n\n  const roots = await all(dagBuilder(buildFileBatch(file, source, block, options), reduce(file, block, options), options))\n\n  if (roots.length > 1) {\n    throw errCode(new Error('expected a maximum of 1 roots and got ' + roots.length), 'ETOOMANYROOTS')\n  }\n\n  return roots[0]\n}\n\nmodule.exports = fileBuilder\n"]},"metadata":{},"sourceType":"script"}