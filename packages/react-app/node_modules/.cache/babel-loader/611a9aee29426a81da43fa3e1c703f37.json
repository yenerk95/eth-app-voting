{"ast":null,"code":"'use strict';\n\nconst {\n  DAGLink,\n  DAGNode\n} = require('ipld-dag-pb');\n\nconst {\n  Buffer\n} = require('buffer');\n\nconst UnixFS = require('ipfs-unixfs');\n\nconst multihashing = require('multihashing-async');\n\nconst Dir = require('./dir');\n\nconst persist = require('./utils/persist');\n\nconst Bucket = require('hamt-sharding');\n\nconst mergeOptions = require('merge-options').bind({\n  ignoreUndefined: true\n});\n\nconst hashFn = async function (value) {\n  const hash = await multihashing(Buffer.from(value, 'utf8'), 'murmur3-128'); // Multihashing inserts preamble of 2 bytes. Remove it.\n  // Also, murmur3 outputs 128 bit but, accidently, IPFS Go's\n  // implementation only uses the first 64, so we must do the same\n  // for parity..\n\n  const justHash = hash.slice(2, 10);\n  const length = justHash.length;\n  const result = Buffer.alloc(length); // TODO: invert buffer because that's how Go impl does it\n\n  for (let i = 0; i < length; i++) {\n    result[length - i - 1] = justHash[i];\n  }\n\n  return result;\n};\n\nhashFn.code = 0x22; // TODO: get this from multihashing-async?\n\nconst defaultOptions = {\n  hamtHashFn: hashFn,\n  hamtBucketBits: 8\n};\n\nclass DirSharded extends Dir {\n  constructor(props, options) {\n    options = mergeOptions(defaultOptions, options);\n    super(props, options);\n    this._bucket = Bucket({\n      hashFn: options.hamtHashFn,\n      bits: options.hamtBucketBits\n    });\n  }\n\n  async put(name, value) {\n    await this._bucket.put(name, value);\n  }\n\n  get(name) {\n    return this._bucket.get(name);\n  }\n\n  childCount() {\n    return this._bucket.leafCount();\n  }\n\n  directChildrenCount() {\n    return this._bucket.childrenCount();\n  }\n\n  onlyChild() {\n    return this._bucket.onlyChild();\n  }\n\n  async *eachChildSeries() {\n    for await (const {\n      key,\n      value\n    } of this._bucket.eachLeafSeries()) {\n      yield {\n        key,\n        child: value\n      };\n    }\n  }\n\n  async *flush(path, block) {\n    for await (const entry of flush(path, this._bucket, block, this, this.options)) {\n      yield entry;\n    }\n  }\n\n}\n\nmodule.exports = DirSharded;\nmodule.exports.hashFn = hashFn;\n\nasync function* flush(path, bucket, block, shardRoot, options) {\n  const children = bucket._children;\n  const links = [];\n  let childrenSize = 0;\n\n  for (let i = 0; i < children.length; i++) {\n    const child = children.get(i);\n\n    if (!child) {\n      continue;\n    }\n\n    const labelPrefix = i.toString(16).toUpperCase().padStart(2, '0');\n\n    if (Bucket.isBucket(child)) {\n      let shard;\n\n      for await (const subShard of await flush('', child, block, null, options)) {\n        shard = subShard;\n      }\n\n      links.push(new DAGLink(labelPrefix, shard.size, shard.cid));\n      childrenSize += shard.size;\n    } else if (typeof child.value.flush === 'function') {\n      const dir = child.value;\n      let flushedDir;\n\n      for await (const entry of dir.flush(dir.path, block)) {\n        flushedDir = entry;\n        yield flushedDir;\n      }\n\n      const label = labelPrefix + child.key;\n      links.push(new DAGLink(label, flushedDir.size, flushedDir.cid));\n      childrenSize += flushedDir.size;\n    } else {\n      const value = child.value;\n\n      if (!value.cid) {\n        continue;\n      }\n\n      const label = labelPrefix + child.key;\n      const size = value.size;\n      links.push(new DAGLink(label, size, value.cid));\n      childrenSize += size;\n    }\n  } // go-ipfs uses little endian, that's why we have to\n  // reverse the bit field before storing it\n\n\n  const data = Buffer.from(children.bitField().reverse());\n  const dir = new UnixFS({\n    type: 'hamt-sharded-directory',\n    data,\n    fanout: bucket.tableSize(),\n    hashType: options.hamtHashFn.code,\n    mtime: shardRoot && shardRoot.mtime,\n    mode: shardRoot && shardRoot.mode\n  });\n  const node = new DAGNode(dir.marshal(), links);\n  const buffer = node.serialize();\n  const cid = await persist(buffer, block, options);\n  const size = buffer.length + childrenSize;\n  yield {\n    cid,\n    unixfs: dir,\n    path,\n    size\n  };\n}","map":{"version":3,"sources":["/Users/yenerkaraca/Documents/GitHub/eth-app/node_modules/ipfs-unixfs-importer/src/dir-sharded.js"],"names":["DAGLink","DAGNode","require","Buffer","UnixFS","multihashing","Dir","persist","Bucket","mergeOptions","bind","ignoreUndefined","hashFn","value","hash","from","justHash","slice","length","result","alloc","i","code","defaultOptions","hamtHashFn","hamtBucketBits","DirSharded","constructor","props","options","_bucket","bits","put","name","get","childCount","leafCount","directChildrenCount","childrenCount","onlyChild","eachChildSeries","key","eachLeafSeries","child","flush","path","block","entry","module","exports","bucket","shardRoot","children","_children","links","childrenSize","labelPrefix","toString","toUpperCase","padStart","isBucket","shard","subShard","push","size","cid","dir","flushedDir","label","data","bitField","reverse","type","fanout","tableSize","hashType","mtime","mode","node","marshal","buffer","serialize","unixfs"],"mappings":"AAAA;;AAEA,MAAM;AACJA,EAAAA,OADI;AAEJC,EAAAA;AAFI,IAGFC,OAAO,CAAC,aAAD,CAHX;;AAIA,MAAM;AAAEC,EAAAA;AAAF,IAAaD,OAAO,CAAC,QAAD,CAA1B;;AACA,MAAME,MAAM,GAAGF,OAAO,CAAC,aAAD,CAAtB;;AACA,MAAMG,YAAY,GAAGH,OAAO,CAAC,oBAAD,CAA5B;;AACA,MAAMI,GAAG,GAAGJ,OAAO,CAAC,OAAD,CAAnB;;AACA,MAAMK,OAAO,GAAGL,OAAO,CAAC,iBAAD,CAAvB;;AACA,MAAMM,MAAM,GAAGN,OAAO,CAAC,eAAD,CAAtB;;AACA,MAAMO,YAAY,GAAGP,OAAO,CAAC,eAAD,CAAP,CAAyBQ,IAAzB,CAA8B;AAAEC,EAAAA,eAAe,EAAE;AAAnB,CAA9B,CAArB;;AAEA,MAAMC,MAAM,GAAG,gBAAgBC,KAAhB,EAAuB;AACpC,QAAMC,IAAI,GAAG,MAAMT,YAAY,CAACF,MAAM,CAACY,IAAP,CAAYF,KAAZ,EAAmB,MAAnB,CAAD,EAA6B,aAA7B,CAA/B,CADoC,CAGpC;AACA;AACA;AACA;;AACA,QAAMG,QAAQ,GAAGF,IAAI,CAACG,KAAL,CAAW,CAAX,EAAc,EAAd,CAAjB;AACA,QAAMC,MAAM,GAAGF,QAAQ,CAACE,MAAxB;AACA,QAAMC,MAAM,GAAGhB,MAAM,CAACiB,KAAP,CAAaF,MAAb,CAAf,CAToC,CAUpC;;AACA,OAAK,IAAIG,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGH,MAApB,EAA4BG,CAAC,EAA7B,EAAiC;AAC/BF,IAAAA,MAAM,CAACD,MAAM,GAAGG,CAAT,GAAa,CAAd,CAAN,GAAyBL,QAAQ,CAACK,CAAD,CAAjC;AACD;;AAED,SAAOF,MAAP;AACD,CAhBD;;AAiBAP,MAAM,CAACU,IAAP,GAAc,IAAd,C,CAAmB;;AAEnB,MAAMC,cAAc,GAAG;AACrBC,EAAAA,UAAU,EAAEZ,MADS;AAErBa,EAAAA,cAAc,EAAE;AAFK,CAAvB;;AAKA,MAAMC,UAAN,SAAyBpB,GAAzB,CAA6B;AAC3BqB,EAAAA,WAAW,CAAEC,KAAF,EAASC,OAAT,EAAkB;AAC3BA,IAAAA,OAAO,GAAGpB,YAAY,CAACc,cAAD,EAAiBM,OAAjB,CAAtB;AAEA,UAAMD,KAAN,EAAaC,OAAb;AAEA,SAAKC,OAAL,GAAetB,MAAM,CAAC;AACpBI,MAAAA,MAAM,EAAEiB,OAAO,CAACL,UADI;AAEpBO,MAAAA,IAAI,EAAEF,OAAO,CAACJ;AAFM,KAAD,CAArB;AAID;;AAED,QAAMO,GAAN,CAAWC,IAAX,EAAiBpB,KAAjB,EAAwB;AACtB,UAAM,KAAKiB,OAAL,CAAaE,GAAb,CAAiBC,IAAjB,EAAuBpB,KAAvB,CAAN;AACD;;AAEDqB,EAAAA,GAAG,CAAED,IAAF,EAAQ;AACT,WAAO,KAAKH,OAAL,CAAaI,GAAb,CAAiBD,IAAjB,CAAP;AACD;;AAEDE,EAAAA,UAAU,GAAI;AACZ,WAAO,KAAKL,OAAL,CAAaM,SAAb,EAAP;AACD;;AAEDC,EAAAA,mBAAmB,GAAI;AACrB,WAAO,KAAKP,OAAL,CAAaQ,aAAb,EAAP;AACD;;AAEDC,EAAAA,SAAS,GAAI;AACX,WAAO,KAAKT,OAAL,CAAaS,SAAb,EAAP;AACD;;AAED,SAAQC,eAAR,GAA2B;AACzB,eAAW,MAAM;AAAEC,MAAAA,GAAF;AAAO5B,MAAAA;AAAP,KAAjB,IAAmC,KAAKiB,OAAL,CAAaY,cAAb,EAAnC,EAAkE;AAChE,YAAM;AACJD,QAAAA,GADI;AAEJE,QAAAA,KAAK,EAAE9B;AAFH,OAAN;AAID;AACF;;AAED,SAAQ+B,KAAR,CAAeC,IAAf,EAAqBC,KAArB,EAA4B;AAC1B,eAAW,MAAMC,KAAjB,IAA0BH,KAAK,CAACC,IAAD,EAAO,KAAKf,OAAZ,EAAqBgB,KAArB,EAA4B,IAA5B,EAAkC,KAAKjB,OAAvC,CAA/B,EAAgF;AAC9E,YAAMkB,KAAN;AACD;AACF;;AA7C0B;;AAgD7BC,MAAM,CAACC,OAAP,GAAiBvB,UAAjB;AAEAsB,MAAM,CAACC,OAAP,CAAerC,MAAf,GAAwBA,MAAxB;;AAEA,gBAAiBgC,KAAjB,CAAwBC,IAAxB,EAA8BK,MAA9B,EAAsCJ,KAAtC,EAA6CK,SAA7C,EAAwDtB,OAAxD,EAAiE;AAC/D,QAAMuB,QAAQ,GAAGF,MAAM,CAACG,SAAxB;AACA,QAAMC,KAAK,GAAG,EAAd;AACA,MAAIC,YAAY,GAAG,CAAnB;;AAEA,OAAK,IAAIlC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG+B,QAAQ,CAAClC,MAA7B,EAAqCG,CAAC,EAAtC,EAA0C;AACxC,UAAMsB,KAAK,GAAGS,QAAQ,CAAClB,GAAT,CAAab,CAAb,CAAd;;AAEA,QAAI,CAACsB,KAAL,EAAY;AACV;AACD;;AAED,UAAMa,WAAW,GAAGnC,CAAC,CAACoC,QAAF,CAAW,EAAX,EAAeC,WAAf,GAA6BC,QAA7B,CAAsC,CAAtC,EAAyC,GAAzC,CAApB;;AAEA,QAAInD,MAAM,CAACoD,QAAP,CAAgBjB,KAAhB,CAAJ,EAA4B;AAC1B,UAAIkB,KAAJ;;AAEA,iBAAW,MAAMC,QAAjB,IAA6B,MAAMlB,KAAK,CAAC,EAAD,EAAKD,KAAL,EAAYG,KAAZ,EAAmB,IAAnB,EAAyBjB,OAAzB,CAAxC,EAA2E;AACzEgC,QAAAA,KAAK,GAAGC,QAAR;AACD;;AAEDR,MAAAA,KAAK,CAACS,IAAN,CAAW,IAAI/D,OAAJ,CAAYwD,WAAZ,EAAyBK,KAAK,CAACG,IAA/B,EAAqCH,KAAK,CAACI,GAA3C,CAAX;AACAV,MAAAA,YAAY,IAAIM,KAAK,CAACG,IAAtB;AACD,KATD,MASO,IAAI,OAAOrB,KAAK,CAAC9B,KAAN,CAAY+B,KAAnB,KAA6B,UAAjC,EAA6C;AAClD,YAAMsB,GAAG,GAAGvB,KAAK,CAAC9B,KAAlB;AACA,UAAIsD,UAAJ;;AAEA,iBAAW,MAAMpB,KAAjB,IAA0BmB,GAAG,CAACtB,KAAJ,CAAUsB,GAAG,CAACrB,IAAd,EAAoBC,KAApB,CAA1B,EAAsD;AACpDqB,QAAAA,UAAU,GAAGpB,KAAb;AAEA,cAAMoB,UAAN;AACD;;AAED,YAAMC,KAAK,GAAGZ,WAAW,GAAGb,KAAK,CAACF,GAAlC;AACAa,MAAAA,KAAK,CAACS,IAAN,CAAW,IAAI/D,OAAJ,CAAYoE,KAAZ,EAAmBD,UAAU,CAACH,IAA9B,EAAoCG,UAAU,CAACF,GAA/C,CAAX;AAEAV,MAAAA,YAAY,IAAIY,UAAU,CAACH,IAA3B;AACD,KAdM,MAcA;AACL,YAAMnD,KAAK,GAAG8B,KAAK,CAAC9B,KAApB;;AAEA,UAAI,CAACA,KAAK,CAACoD,GAAX,EAAgB;AACd;AACD;;AAED,YAAMG,KAAK,GAAGZ,WAAW,GAAGb,KAAK,CAACF,GAAlC;AACA,YAAMuB,IAAI,GAAGnD,KAAK,CAACmD,IAAnB;AAEAV,MAAAA,KAAK,CAACS,IAAN,CAAW,IAAI/D,OAAJ,CAAYoE,KAAZ,EAAmBJ,IAAnB,EAAyBnD,KAAK,CAACoD,GAA/B,CAAX;AACAV,MAAAA,YAAY,IAAIS,IAAhB;AACD;AACF,GAlD8D,CAoD/D;AACA;;;AACA,QAAMK,IAAI,GAAGlE,MAAM,CAACY,IAAP,CAAYqC,QAAQ,CAACkB,QAAT,GAAoBC,OAApB,EAAZ,CAAb;AACA,QAAML,GAAG,GAAG,IAAI9D,MAAJ,CAAW;AACrBoE,IAAAA,IAAI,EAAE,wBADe;AAErBH,IAAAA,IAFqB;AAGrBI,IAAAA,MAAM,EAAEvB,MAAM,CAACwB,SAAP,EAHa;AAIrBC,IAAAA,QAAQ,EAAE9C,OAAO,CAACL,UAAR,CAAmBF,IAJR;AAKrBsD,IAAAA,KAAK,EAAEzB,SAAS,IAAIA,SAAS,CAACyB,KALT;AAMrBC,IAAAA,IAAI,EAAE1B,SAAS,IAAIA,SAAS,CAAC0B;AANR,GAAX,CAAZ;AASA,QAAMC,IAAI,GAAG,IAAI7E,OAAJ,CAAYiE,GAAG,CAACa,OAAJ,EAAZ,EAA2BzB,KAA3B,CAAb;AACA,QAAM0B,MAAM,GAAGF,IAAI,CAACG,SAAL,EAAf;AACA,QAAMhB,GAAG,GAAG,MAAM1D,OAAO,CAACyE,MAAD,EAASlC,KAAT,EAAgBjB,OAAhB,CAAzB;AACA,QAAMmC,IAAI,GAAGgB,MAAM,CAAC9D,MAAP,GAAgBqC,YAA7B;AAEA,QAAM;AACJU,IAAAA,GADI;AAEJiB,IAAAA,MAAM,EAAEhB,GAFJ;AAGJrB,IAAAA,IAHI;AAIJmB,IAAAA;AAJI,GAAN;AAMD","sourcesContent":["'use strict'\n\nconst {\n  DAGLink,\n  DAGNode\n} = require('ipld-dag-pb')\nconst { Buffer } = require('buffer')\nconst UnixFS = require('ipfs-unixfs')\nconst multihashing = require('multihashing-async')\nconst Dir = require('./dir')\nconst persist = require('./utils/persist')\nconst Bucket = require('hamt-sharding')\nconst mergeOptions = require('merge-options').bind({ ignoreUndefined: true })\n\nconst hashFn = async function (value) {\n  const hash = await multihashing(Buffer.from(value, 'utf8'), 'murmur3-128')\n\n  // Multihashing inserts preamble of 2 bytes. Remove it.\n  // Also, murmur3 outputs 128 bit but, accidently, IPFS Go's\n  // implementation only uses the first 64, so we must do the same\n  // for parity..\n  const justHash = hash.slice(2, 10)\n  const length = justHash.length\n  const result = Buffer.alloc(length)\n  // TODO: invert buffer because that's how Go impl does it\n  for (let i = 0; i < length; i++) {\n    result[length - i - 1] = justHash[i]\n  }\n\n  return result\n}\nhashFn.code = 0x22 // TODO: get this from multihashing-async?\n\nconst defaultOptions = {\n  hamtHashFn: hashFn,\n  hamtBucketBits: 8\n}\n\nclass DirSharded extends Dir {\n  constructor (props, options) {\n    options = mergeOptions(defaultOptions, options)\n\n    super(props, options)\n\n    this._bucket = Bucket({\n      hashFn: options.hamtHashFn,\n      bits: options.hamtBucketBits\n    })\n  }\n\n  async put (name, value) {\n    await this._bucket.put(name, value)\n  }\n\n  get (name) {\n    return this._bucket.get(name)\n  }\n\n  childCount () {\n    return this._bucket.leafCount()\n  }\n\n  directChildrenCount () {\n    return this._bucket.childrenCount()\n  }\n\n  onlyChild () {\n    return this._bucket.onlyChild()\n  }\n\n  async * eachChildSeries () {\n    for await (const { key, value } of this._bucket.eachLeafSeries()) {\n      yield {\n        key,\n        child: value\n      }\n    }\n  }\n\n  async * flush (path, block) {\n    for await (const entry of flush(path, this._bucket, block, this, this.options)) {\n      yield entry\n    }\n  }\n}\n\nmodule.exports = DirSharded\n\nmodule.exports.hashFn = hashFn\n\nasync function * flush (path, bucket, block, shardRoot, options) {\n  const children = bucket._children\n  const links = []\n  let childrenSize = 0\n\n  for (let i = 0; i < children.length; i++) {\n    const child = children.get(i)\n\n    if (!child) {\n      continue\n    }\n\n    const labelPrefix = i.toString(16).toUpperCase().padStart(2, '0')\n\n    if (Bucket.isBucket(child)) {\n      let shard\n\n      for await (const subShard of await flush('', child, block, null, options)) {\n        shard = subShard\n      }\n\n      links.push(new DAGLink(labelPrefix, shard.size, shard.cid))\n      childrenSize += shard.size\n    } else if (typeof child.value.flush === 'function') {\n      const dir = child.value\n      let flushedDir\n\n      for await (const entry of dir.flush(dir.path, block)) {\n        flushedDir = entry\n\n        yield flushedDir\n      }\n\n      const label = labelPrefix + child.key\n      links.push(new DAGLink(label, flushedDir.size, flushedDir.cid))\n\n      childrenSize += flushedDir.size\n    } else {\n      const value = child.value\n\n      if (!value.cid) {\n        continue\n      }\n\n      const label = labelPrefix + child.key\n      const size = value.size\n\n      links.push(new DAGLink(label, size, value.cid))\n      childrenSize += size\n    }\n  }\n\n  // go-ipfs uses little endian, that's why we have to\n  // reverse the bit field before storing it\n  const data = Buffer.from(children.bitField().reverse())\n  const dir = new UnixFS({\n    type: 'hamt-sharded-directory',\n    data,\n    fanout: bucket.tableSize(),\n    hashType: options.hamtHashFn.code,\n    mtime: shardRoot && shardRoot.mtime,\n    mode: shardRoot && shardRoot.mode\n  })\n\n  const node = new DAGNode(dir.marshal(), links)\n  const buffer = node.serialize()\n  const cid = await persist(buffer, block, options)\n  const size = buffer.length + childrenSize\n\n  yield {\n    cid,\n    unixfs: dir,\n    path,\n    size\n  }\n}\n"]},"metadata":{},"sourceType":"script"}