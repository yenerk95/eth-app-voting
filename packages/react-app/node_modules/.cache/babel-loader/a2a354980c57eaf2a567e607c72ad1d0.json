{"ast":null,"code":"'use strict';\n\nconst {\n  Buffer\n} = require('buffer');\n\nconst BufferList = require('bl/BufferList');\n\nconst lp = require('it-length-prefixed');\n\nconst pipe = require('it-pipe');\n\nconst errCode = require('err-code');\n\nconst NewLine = Buffer.from('\\n');\n\nasync function oneChunk(source) {\n  for await (const chunk of source) return chunk; // We only need one!\n\n}\n\nexports.encode = buffer => lp.encode.single(new BufferList([buffer, NewLine])); // `write` encodes and writes a single buffer\n\n\nexports.write = (writer, buffer) => writer.push(exports.encode(buffer)); // `writeAll` behaves like `write`, except it encodes an array of items as a single write\n\n\nexports.writeAll = (writer, buffers) => {\n  writer.push(buffers.reduce((bl, buffer) => bl.append(exports.encode(buffer)), new BufferList()));\n};\n\nexports.read = async reader => {\n  let byteLength = 1; // Read single byte chunks until the length is known\n\n  const varByteSource = {\n    // No return impl - we want the reader to remain readable\n    [Symbol.asyncIterator]() {\n      return this;\n    },\n\n    next: () => reader.next(byteLength)\n  }; // Once the length has been parsed, read chunk for that length\n\n  const onLength = l => {\n    byteLength = l;\n  };\n\n  const buf = await pipe(varByteSource, lp.decode({\n    onLength\n  }), oneChunk);\n\n  if (buf.get(buf.length - 1) !== NewLine[0]) {\n    throw errCode(new Error('missing newline'), 'ERR_INVALID_MULTISTREAM_SELECT_MESSAGE');\n  }\n\n  return buf.shallowSlice(0, -1); // Remove newline\n};","map":{"version":3,"sources":["/Users/yenerkaraca/Documents/GitHub/eth-app/node_modules/multistream-select/src/multistream.js"],"names":["Buffer","require","BufferList","lp","pipe","errCode","NewLine","from","oneChunk","source","chunk","exports","encode","buffer","single","write","writer","push","writeAll","buffers","reduce","bl","append","read","reader","byteLength","varByteSource","Symbol","asyncIterator","next","onLength","l","buf","decode","get","length","Error","shallowSlice"],"mappings":"AAAA;;AAEA,MAAM;AAAEA,EAAAA;AAAF,IAAaC,OAAO,CAAC,QAAD,CAA1B;;AACA,MAAMC,UAAU,GAAGD,OAAO,CAAC,eAAD,CAA1B;;AACA,MAAME,EAAE,GAAGF,OAAO,CAAC,oBAAD,CAAlB;;AACA,MAAMG,IAAI,GAAGH,OAAO,CAAC,SAAD,CAApB;;AACA,MAAMI,OAAO,GAAGJ,OAAO,CAAC,UAAD,CAAvB;;AAEA,MAAMK,OAAO,GAAGN,MAAM,CAACO,IAAP,CAAY,IAAZ,CAAhB;;AAEA,eAAeC,QAAf,CAAyBC,MAAzB,EAAiC;AAC/B,aAAW,MAAMC,KAAjB,IAA0BD,MAA1B,EAAkC,OAAOC,KAAP,CADH,CACgB;;AAChD;;AAEDC,OAAO,CAACC,MAAR,GAAiBC,MAAM,IAAIV,EAAE,CAACS,MAAH,CAAUE,MAAV,CAAiB,IAAIZ,UAAJ,CAAe,CAACW,MAAD,EAASP,OAAT,CAAf,CAAjB,CAA3B,C,CAEA;;;AACAK,OAAO,CAACI,KAAR,GAAgB,CAACC,MAAD,EAASH,MAAT,KAAoBG,MAAM,CAACC,IAAP,CAAYN,OAAO,CAACC,MAAR,CAAeC,MAAf,CAAZ,CAApC,C,CAEA;;;AACAF,OAAO,CAACO,QAAR,GAAmB,CAACF,MAAD,EAASG,OAAT,KAAqB;AACtCH,EAAAA,MAAM,CAACC,IAAP,CAAYE,OAAO,CAACC,MAAR,CAAe,CAACC,EAAD,EAAKR,MAAL,KAAgBQ,EAAE,CAACC,MAAH,CAAUX,OAAO,CAACC,MAAR,CAAeC,MAAf,CAAV,CAA/B,EAAkE,IAAIX,UAAJ,EAAlE,CAAZ;AACD,CAFD;;AAIAS,OAAO,CAACY,IAAR,GAAe,MAAMC,MAAN,IAAgB;AAC7B,MAAIC,UAAU,GAAG,CAAjB,CAD6B,CACV;;AACnB,QAAMC,aAAa,GAAG;AAAE;AACtB,KAACC,MAAM,CAACC,aAAR,IAA0B;AAAE,aAAO,IAAP;AAAa,KADrB;;AAEpBC,IAAAA,IAAI,EAAE,MAAML,MAAM,CAACK,IAAP,CAAYJ,UAAZ;AAFQ,GAAtB,CAF6B,CAO7B;;AACA,QAAMK,QAAQ,GAAGC,CAAC,IAAI;AAAEN,IAAAA,UAAU,GAAGM,CAAb;AAAgB,GAAxC;;AACA,QAAMC,GAAG,GAAG,MAAM5B,IAAI,CAACsB,aAAD,EAAgBvB,EAAE,CAAC8B,MAAH,CAAU;AAAEH,IAAAA;AAAF,GAAV,CAAhB,EAAyCtB,QAAzC,CAAtB;;AAEA,MAAIwB,GAAG,CAACE,GAAJ,CAAQF,GAAG,CAACG,MAAJ,GAAa,CAArB,MAA4B7B,OAAO,CAAC,CAAD,CAAvC,EAA4C;AAC1C,UAAMD,OAAO,CAAC,IAAI+B,KAAJ,CAAU,iBAAV,CAAD,EAA+B,wCAA/B,CAAb;AACD;;AAED,SAAOJ,GAAG,CAACK,YAAJ,CAAiB,CAAjB,EAAoB,CAAC,CAArB,CAAP,CAf6B,CAeE;AAChC,CAhBD","sourcesContent":["'use strict'\n\nconst { Buffer } = require('buffer')\nconst BufferList = require('bl/BufferList')\nconst lp = require('it-length-prefixed')\nconst pipe = require('it-pipe')\nconst errCode = require('err-code')\n\nconst NewLine = Buffer.from('\\n')\n\nasync function oneChunk (source) {\n  for await (const chunk of source) return chunk // We only need one!\n}\n\nexports.encode = buffer => lp.encode.single(new BufferList([buffer, NewLine]))\n\n// `write` encodes and writes a single buffer\nexports.write = (writer, buffer) => writer.push(exports.encode(buffer))\n\n// `writeAll` behaves like `write`, except it encodes an array of items as a single write\nexports.writeAll = (writer, buffers) => {\n  writer.push(buffers.reduce((bl, buffer) => bl.append(exports.encode(buffer)), new BufferList()))\n}\n\nexports.read = async reader => {\n  let byteLength = 1 // Read single byte chunks until the length is known\n  const varByteSource = { // No return impl - we want the reader to remain readable\n    [Symbol.asyncIterator] () { return this },\n    next: () => reader.next(byteLength)\n  }\n\n  // Once the length has been parsed, read chunk for that length\n  const onLength = l => { byteLength = l }\n  const buf = await pipe(varByteSource, lp.decode({ onLength }), oneChunk)\n\n  if (buf.get(buf.length - 1) !== NewLine[0]) {\n    throw errCode(new Error('missing newline'), 'ERR_INVALID_MULTISTREAM_SELECT_MESSAGE')\n  }\n\n  return buf.shallowSlice(0, -1) // Remove newline\n}\n"]},"metadata":{},"sourceType":"script"}